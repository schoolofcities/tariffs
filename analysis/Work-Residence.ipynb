{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b1c8a3-9dc5-4fa0-b61b-895477a018b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f41f1-68d6-44d1-b3dc-b9c8cd1f9056",
   "metadata": {},
   "source": [
    "# STEP 3: Connecting Tariffed HS Codes, NAICS Codes and respective CUSMA Non-Utilisation Rates via Concordance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa764029-c2f2-4aa6-a780-78fdc71307d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tariffed = pd.read_csv('tariff-hscodes.csv', encoding_errors='ignore', dtype={'HS Code': str})\n",
    "\n",
    "tariffed['HS_Code_6digit'] = (\n",
    "    tariffed['HS Code']\n",
    "    .str.replace('.', '', regex=False)\n",
    "    .str[:6]\n",
    ")\n",
    "\n",
    "tariffed = tariffed[['HS_Code_6digit', 'Category']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e34b98-821b-4c25-8f01-631b3f80349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = pd.read_csv('C616_HS8toNaics6_concord_202505.csv', dtype={'hts10': str})\n",
    "\n",
    "concordance['HS_Code_6digit'] = (\n",
    "    concordance['HS8 Code']\n",
    "    .astype(str)\n",
    "    .str.zfill(8)\n",
    "    .str[:6]\n",
    ")\n",
    "\n",
    "concordance['HS_Code_2digit'] = (\n",
    "    concordance['HS8 Code']\n",
    "    .astype(str)\n",
    "    .str.zfill(8)\n",
    "    .str[:2]\n",
    ")\n",
    "\n",
    "concordance['naics'] = concordance['NAICS 6 Code'].astype(str)\n",
    "\n",
    "concordance = concordance[['HS_Code_6digit', 'naics', 'HS_Code_2digit']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66352da6-6063-4f50-bea7-943a80938373",
   "metadata": {},
   "outputs": [],
   "source": [
    "util = pd.read_csv('USMCA Utilization Data.csv')\n",
    "\n",
    "util['HS_Code_2digit'] = (\n",
    "    util['HS Classification']\n",
    "    .astype(str)\n",
    "    .str[:2]\n",
    ")\n",
    "\n",
    "util['nonutil_rate'] = util['USMCA_Nonutilisation_May2025']\n",
    "\n",
    "util = util[['HS_Code_2digit', 'nonutil_rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b5582-14de-46e7-a267-3e63d87bf692",
   "metadata": {},
   "source": [
    "Setting the non-utilisation rate for those with sectoral tariffs at 1 reflects the fact that the 35% tariffs on non-CUSMA goods does not apply to the sectoral tariffs and that producers impacted by sectoral tariffs cannot use CUSMA to get their goods tariff-free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31aa998-e417-4eb6-9552-0c25e8ff265b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS_Code_6digit</th>\n",
       "      <th>naics</th>\n",
       "      <th>HS_Code_2digit</th>\n",
       "      <th>Category</th>\n",
       "      <th>count</th>\n",
       "      <th>nonutil_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010110</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010121</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010129</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010130</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010190</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>961620</td>\n",
       "      <td>314990</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6970</th>\n",
       "      <td>961700</td>\n",
       "      <td>332439</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6971</th>\n",
       "      <td>961800</td>\n",
       "      <td>339990</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6972</th>\n",
       "      <td>961900</td>\n",
       "      <td>322291</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>962000</td>\n",
       "      <td>322291</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6974 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HS_Code_6digit   naics HS_Code_2digit Category  count  nonutil_rate\n",
       "0            010110  112920             01      NaN      1          0.42\n",
       "1            010121  112920             01      NaN      1          0.42\n",
       "2            010129  112920             01      NaN      1          0.42\n",
       "3            010130  112920             01      NaN      1          0.42\n",
       "4            010190  112920             01      NaN      1          0.42\n",
       "...             ...     ...            ...      ...    ...           ...\n",
       "6969         961620  314990             96      NaN      1          0.84\n",
       "6970         961700  332439             96      NaN      1          0.84\n",
       "6971         961800  339990             96      NaN      1          0.84\n",
       "6972         961900  322291             96      NaN      1          0.84\n",
       "6973         962000  322291             96      NaN      1          0.84\n",
       "\n",
       "[6974 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naics_tar = concordance.merge(tariffed, on='HS_Code_6digit', how='left')\n",
    "\n",
    "counts = naics_tar['HS_Code_6digit'].value_counts().reset_index()\n",
    "naics_tarc = naics_tar.merge(counts, on='HS_Code_6digit', how='left')\n",
    "\n",
    "naics_imp = naics_tarc.merge(util, on='HS_Code_2digit', how='left')\n",
    "\n",
    "# Making the codes with a sectoral tariff category assigned to have a non-util rate value of 1\n",
    "# This ensures that when multiplied later, sectoral tariffs do not affect the CUSMA non-utilisation rates to compute the impact of nonCUSMA 35% tariffs\n",
    "naics_imp.loc[naics_imp['Category'].notna(), 'nonutil_rate'] = 1\n",
    "naics_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe76b5c-45df-4f0a-9bdb-f4a64be60a5c",
   "metadata": {},
   "source": [
    "# STEP 4: Getting Weights by Province/Territory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a5831-a579-4abf-8500-04124e5d4c93",
   "metadata": {},
   "source": [
    "Since multiple NAICS codes may contribute to the production of one HS code product, and we do not how much of a part does each NAICS contribute to the whole HS code good production, **thus an assumption is made to divide them equally**. Hence, when each export value is added, it is divided them by the count (how many times does that HS Code get repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f7ef2c-1f20-4934-bdf9-19de81ca172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS_Code_6digit</th>\n",
       "      <th>naics</th>\n",
       "      <th>nonutil_rate</th>\n",
       "      <th>NL_Global</th>\n",
       "      <th>NL_US</th>\n",
       "      <th>PEI_Global</th>\n",
       "      <th>PEI_US</th>\n",
       "      <th>NS_Global</th>\n",
       "      <th>NS_US</th>\n",
       "      <th>NB_Global</th>\n",
       "      <th>...</th>\n",
       "      <th>AL_Global</th>\n",
       "      <th>AL_US</th>\n",
       "      <th>BC_Global</th>\n",
       "      <th>BC_US</th>\n",
       "      <th>YK_Global</th>\n",
       "      <th>YK_US</th>\n",
       "      <th>NWT_Global</th>\n",
       "      <th>NWT_US</th>\n",
       "      <th>NU_Global</th>\n",
       "      <th>NU_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010110</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010121</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102006.0</td>\n",
       "      <td>102006.0</td>\n",
       "      <td>43608.0</td>\n",
       "      <td>43608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010129</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103341.0</td>\n",
       "      <td>103341.0</td>\n",
       "      <td>767570.0</td>\n",
       "      <td>767570.0</td>\n",
       "      <td>245243.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38107217.0</td>\n",
       "      <td>16300710.0</td>\n",
       "      <td>8940055.0</td>\n",
       "      <td>8863555.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010130</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16453.0</td>\n",
       "      <td>16453.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010190</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>961620</td>\n",
       "      <td>314990</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26374.0</td>\n",
       "      <td>23452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6970</th>\n",
       "      <td>961700</td>\n",
       "      <td>332439</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>191510.0</td>\n",
       "      <td>69403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6971</th>\n",
       "      <td>961800</td>\n",
       "      <td>339990</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57388.0</td>\n",
       "      <td>36336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6972</th>\n",
       "      <td>961900</td>\n",
       "      <td>322291</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113029441.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10736.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>408726.0</td>\n",
       "      <td>5790.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>962000</td>\n",
       "      <td>322291</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20243.0</td>\n",
       "      <td>20243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>169613.0</td>\n",
       "      <td>98149.0</td>\n",
       "      <td>6675.0</td>\n",
       "      <td>3721.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6974 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HS_Code_6digit   naics  nonutil_rate  NL_Global  NL_US  PEI_Global  \\\n",
       "0            010110  112920          0.42        0.0    0.0         0.0   \n",
       "1            010121  112920          0.42        0.0    0.0         0.0   \n",
       "2            010129  112920          0.42        0.0    0.0    103341.0   \n",
       "3            010130  112920          0.42        0.0    0.0         0.0   \n",
       "4            010190  112920          0.42        0.0    0.0         0.0   \n",
       "...             ...     ...           ...        ...    ...         ...   \n",
       "6969         961620  314990          0.84        0.0    0.0         0.0   \n",
       "6970         961700  332439          0.84        0.0    0.0         0.0   \n",
       "6971         961800  339990          0.84        0.0    0.0         0.0   \n",
       "6972         961900  322291          0.84        0.0    0.0         0.0   \n",
       "6973         962000  322291          0.84        0.0    0.0         0.0   \n",
       "\n",
       "        PEI_US  NS_Global     NS_US    NB_Global  ...   AL_Global       AL_US  \\\n",
       "0          0.0        0.0       0.0          0.0  ...         0.0         0.0   \n",
       "1          0.0        0.0       0.0          0.0  ...    102006.0    102006.0   \n",
       "2     103341.0   767570.0  767570.0     245243.0  ...  38107217.0  16300710.0   \n",
       "3          0.0        0.0       0.0       5591.0  ...         0.0         0.0   \n",
       "4          0.0        0.0       0.0          0.0  ...         0.0         0.0   \n",
       "...        ...        ...       ...          ...  ...         ...         ...   \n",
       "6969       0.0        0.0       0.0          0.0  ...         0.0         0.0   \n",
       "6970       0.0        9.0       0.0          0.0  ...      4454.0      4454.0   \n",
       "6971       0.0        0.0       0.0          0.0  ...         0.0         0.0   \n",
       "6972       0.0        0.0       0.0  113029441.0  ...     10736.0         0.0   \n",
       "6973       0.0    20243.0   20243.0          0.0  ...    169613.0     98149.0   \n",
       "\n",
       "      BC_Global      BC_US  YK_Global  YK_US  NWT_Global  NWT_US  NU_Global  \\\n",
       "0           0.0        0.0        0.0    0.0         0.0     0.0        0.0   \n",
       "1       43608.0    43608.0        0.0    0.0         0.0     0.0        0.0   \n",
       "2     8940055.0  8863555.0        0.0    0.0         0.0     0.0        0.0   \n",
       "3       16453.0    16453.0        0.0    0.0         0.0     0.0        0.0   \n",
       "4           0.0        0.0        0.0    0.0         0.0     0.0        0.0   \n",
       "...         ...        ...        ...    ...         ...     ...        ...   \n",
       "6969    26374.0    23452.0        0.0    0.0         0.0     0.0        0.0   \n",
       "6970   191510.0    69403.0        0.0    0.0         0.0     0.0        0.0   \n",
       "6971    57388.0    36336.0        0.0    0.0         0.0     0.0        0.0   \n",
       "6972   408726.0     5790.0        0.0    0.0         0.0     0.0        0.0   \n",
       "6973     6675.0     3721.0        0.0    0.0         0.0     0.0        0.0   \n",
       "\n",
       "      NU_US  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "6969    0.0  \n",
       "6970    0.0  \n",
       "6971    0.0  \n",
       "6972    0.0  \n",
       "6973    0.0  \n",
       "\n",
       "[6974 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the DataFrame with NAICS data\n",
    "tariff_exp_val = naics_imp.copy()\n",
    "\n",
    "# Define all regions to process\n",
    "regions = ['NL', 'PEI', 'NS', 'NB', 'QC', 'ON', 'MB', 'SK', 'AL', 'BC', 'YK', 'NWT', 'NU']\n",
    "cols = ['Commodity', 'Value ($)']\n",
    "\n",
    "for region in regions:\n",
    "    # Process Global data\n",
    "    global_df = pd.read_csv(f'{region}-Global.csv', usecols=cols)\n",
    "    global_df['HS_Code_6digit'] = global_df['Commodity'].str.replace('.', '', regex=False).str[:6]\n",
    "    global_df[f'{region}_Global'] = global_df['Value ($)']\n",
    "    global_df = global_df[['HS_Code_6digit', f'{region}_Global']]\n",
    "    \n",
    "    tariff_exp_val = tariff_exp_val.merge(global_df, on='HS_Code_6digit', how='left')\n",
    "    tariff_exp_val[f'{region}_Global'] = tariff_exp_val[f'{region}_Global'] / tariff_exp_val['count']\n",
    "    \n",
    "    # Process US data\n",
    "    us_df = pd.read_csv(f'{region}-US.csv', usecols=cols)\n",
    "    us_df['HS_Code_6digit'] = us_df['Commodity'].str.replace('.', '', regex=False).str[:6]\n",
    "    us_df[f'{region}_US'] = us_df['Value ($)']\n",
    "    us_df = us_df[['HS_Code_6digit', f'{region}_US']]\n",
    "    \n",
    "    tariff_exp_val = tariff_exp_val.merge(us_df, on='HS_Code_6digit', how='left')\n",
    "    tariff_exp_val[f'{region}_US'] = tariff_exp_val[f'{region}_US'] / tariff_exp_val['count']\n",
    "\n",
    "# Drop the non-relevant columns\n",
    "tariff_exp_val = tariff_exp_val.drop(columns=['HS_Code_2digit', 'Category', 'count'])\n",
    "\n",
    "tariff_exp_val = tariff_exp_val.fillna(0)\n",
    "\n",
    "tariff_exp_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fd10f-2d47-43a0-b19c-eb885c577b5a",
   "metadata": {},
   "source": [
    "The formula to calculate the weights is a ratio of US exports to Global exports, which is then multiplied by the respective CUSMA non-utilisation rate.  \n",
    "  \n",
    "We are taking the assumption that **the non-utilisation rate for each NAICS code is set at the mean, and it is not weighted**. This is because non-utilisation rate is first given to HS Codes, and each NAICS industry can produce products across different HS Codes and therefore each of their product exports may have different non-utilisation rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6afb068-7004-48f2-bdd8-d36f5556b5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics</th>\n",
       "      <th>NL_Rate</th>\n",
       "      <th>PEI_Rate</th>\n",
       "      <th>NS_Rate</th>\n",
       "      <th>NB_Rate</th>\n",
       "      <th>QC_Rate</th>\n",
       "      <th>ON_Rate</th>\n",
       "      <th>MB_Rate</th>\n",
       "      <th>SK_Rate</th>\n",
       "      <th>AL_Rate</th>\n",
       "      <th>BC_Rate</th>\n",
       "      <th>YK_Rate</th>\n",
       "      <th>NWT_Rate</th>\n",
       "      <th>NU_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>0.064938</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111120</td>\n",
       "      <td>0.678462</td>\n",
       "      <td>0.678462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136710</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.406677</td>\n",
       "      <td>0.103250</td>\n",
       "      <td>0.052447</td>\n",
       "      <td>0.037429</td>\n",
       "      <td>0.031443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405714</td>\n",
       "      <td>0.405714</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.033932</td>\n",
       "      <td>0.032811</td>\n",
       "      <td>0.042095</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194542</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.243865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>339920</td>\n",
       "      <td>0.481951</td>\n",
       "      <td>0.296708</td>\n",
       "      <td>0.536874</td>\n",
       "      <td>0.149737</td>\n",
       "      <td>0.484751</td>\n",
       "      <td>0.417990</td>\n",
       "      <td>0.457369</td>\n",
       "      <td>0.482840</td>\n",
       "      <td>0.531677</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.548929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>339930</td>\n",
       "      <td>0.337158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372909</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.326389</td>\n",
       "      <td>0.233975</td>\n",
       "      <td>0.316760</td>\n",
       "      <td>0.384623</td>\n",
       "      <td>0.346251</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>339940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048109</td>\n",
       "      <td>0.804283</td>\n",
       "      <td>0.498074</td>\n",
       "      <td>0.731903</td>\n",
       "      <td>0.809208</td>\n",
       "      <td>0.812800</td>\n",
       "      <td>0.701242</td>\n",
       "      <td>0.726585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>339950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.667704</td>\n",
       "      <td>0.642297</td>\n",
       "      <td>0.651382</td>\n",
       "      <td>0.639883</td>\n",
       "      <td>0.663664</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.470009</td>\n",
       "      <td>0.598870</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>339990</td>\n",
       "      <td>0.106638</td>\n",
       "      <td>0.670449</td>\n",
       "      <td>0.545332</td>\n",
       "      <td>0.498666</td>\n",
       "      <td>0.516122</td>\n",
       "      <td>0.608112</td>\n",
       "      <td>0.574522</td>\n",
       "      <td>0.508794</td>\n",
       "      <td>0.469975</td>\n",
       "      <td>0.349176</td>\n",
       "      <td>0.683868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      naics   NL_Rate  PEI_Rate   NS_Rate   NB_Rate   QC_Rate   ON_Rate  \\\n",
       "0    111110  0.000000  0.000000  0.000000  0.620000  0.016695  0.057076   \n",
       "1    111120  0.678462  0.678462  0.000000  0.136710  0.043700  0.406677   \n",
       "2    111130  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3    111140  0.000000  0.000000  0.405714  0.405714  0.042229  0.033932   \n",
       "4    111150  0.000000  0.000000  0.000000  0.000000  0.194542  0.074227   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "305  339920  0.481951  0.296708  0.536874  0.149737  0.484751  0.417990   \n",
       "306  339930  0.337158  0.000000  0.372909  0.394500  0.326389  0.233975   \n",
       "307  339940  0.000000  0.000000  0.048109  0.804283  0.498074  0.731903   \n",
       "308  339950  0.000000  0.668000  0.667704  0.642297  0.651382  0.639883   \n",
       "309  339990  0.106638  0.670449  0.545332  0.498666  0.516122  0.608112   \n",
       "\n",
       "      MB_Rate   SK_Rate   AL_Rate   BC_Rate   YK_Rate  NWT_Rate   NU_Rate  \n",
       "0    0.064938  0.000728  0.024138  0.000000  0.000000       0.0  0.000000  \n",
       "1    0.103250  0.052447  0.037429  0.031443  0.000000       0.0  0.000000  \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.000000       0.0  0.000000  \n",
       "3    0.032811  0.042095  0.035477  0.031522  0.000000       0.0  0.000000  \n",
       "4    0.370000  0.000000  0.370000  0.243865  0.000000       0.0  0.000000  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "305  0.457369  0.482840  0.531677  0.409661  0.548929       0.0  0.000000  \n",
       "306  0.316760  0.384623  0.346251  0.241962  0.000000       0.0  0.394500  \n",
       "307  0.809208  0.812800  0.701242  0.726585  0.000000       0.0  0.000000  \n",
       "308  0.663664  0.668000  0.470009  0.598870  0.668000       0.0  0.668000  \n",
       "309  0.574522  0.508794  0.469975  0.349176  0.683868       0.0  0.683868  \n",
       "\n",
       "[310 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Aggregate ONLY the necessary sums (Global/US columns)\n",
    "aggregates = {\n",
    "    **{f'{region}_Global': (f'{region}_Global', 'sum') for region in regions},\n",
    "    **{f'{region}_US': (f'{region}_US', 'sum') for region in regions},\n",
    "    'nonutil_rate':   ('nonutil_rate', 'mean')\n",
    "}\n",
    "\n",
    "weight_naics = tariff_exp_val.groupby('naics', as_index=False).agg(**aggregates)\n",
    "\n",
    "# Step 2: Compute rates and keep ONLY those columns\n",
    "for region in regions:\n",
    "    global_col = f'{region}_Global'\n",
    "    us_col = f'{region}_US'\n",
    "    rate_col = f'{region}_Rate'\n",
    "    \n",
    "    weight_naics[rate_col] = (\n",
    "        weight_naics[us_col] / weight_naics[global_col] * weight_naics['nonutil_rate']\n",
    "    )\n",
    "\n",
    "# Step 3: Select only naics, naics_2digit, and rate columns\n",
    "final_columns = ['naics'] + [f'{region}_Rate' for region in regions]\n",
    "weight_naics = weight_naics[final_columns]\n",
    "weight_naics = weight_naics.fillna(0)\n",
    "\n",
    "# Result\n",
    "weight_naics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5357b847-43c8-4210-ad77-ce15d87fbd1a",
   "metadata": {},
   "source": [
    "# STEP 5: Using filtered NAICS Codes to filter directly-impacted businesses and estimate directly-impacted employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542741f5-cdbb-4940-8eef-4fa2678f2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_naics = set(naics_imp[naics_imp['Category'] == 'Auto']['naics'].unique())\n",
    "alum_naics = set(naics_imp[naics_imp['Category'] == 'Aluminum']['naics'].unique())\n",
    "steel_naics = set(naics_imp[naics_imp['Category'] == 'Steel']['naics'].unique())\n",
    "copper_naics = set(naics_imp[naics_imp['Category'] == 'Copper']['naics'].unique())\n",
    "lum_naics = set(naics_imp[naics_imp['Category'] == 'Lumber']['naics'].unique())\n",
    "ene_naics = set(naics_imp[naics_imp['Category'] == 'Energy Mineral']['naics'].unique())\n",
    "noncusma_naics = set(naics_imp[naics_imp['Category'].isna()]['naics'].unique())\n",
    "total_naics = set(naics_imp['naics'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08840c94-33b1-4944-94c8-09a34ca11fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_i = ['DA',\n",
    "        'All_Businesses', 'All_Employees',\n",
    "        'Auto_B', 'Auto_E',\n",
    "        'Alum_B', 'Alum_E',\n",
    "        'Steel_B', 'Steel_E',\n",
    "        'Cop_B', 'Cop_E',\n",
    "        'Lum_B', 'Lum_E',\n",
    "        'Ene_B', 'Ene_E',\n",
    "        'CUSMA_B', 'CUSMA_E',\n",
    "        'Total_B', 'Total_E',\n",
    "        #add columns here, column titles are every value of total_naics\n",
    "       ]\n",
    "\n",
    "# Add individual NAICS codes as column headers for Est_Employees by NAICS\n",
    "col_i.extend(sorted(total_naics))\n",
    "\n",
    "business = pd.DataFrame(columns = col_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb75018-9e57-4f0a-b9e6-0c6f9979cfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 processed in 161.32 seconds\n",
      "Chunk 2 processed in 143.50 seconds\n",
      "Chunk 3 processed in 145.32 seconds\n",
      "Chunk 4 processed in 139.92 seconds\n",
      "Chunk 5 processed in 135.22 seconds\n",
      "Chunk 6 processed in 132.87 seconds\n",
      "Chunk 7 processed in 134.25 seconds\n",
      "Chunk 8 processed in 134.69 seconds\n",
      "Chunk 9 processed in 133.66 seconds\n",
      "Chunk 10 processed in 133.06 seconds\n",
      "Chunk 11 processed in 133.74 seconds\n",
      "Chunk 12 processed in 133.08 seconds\n",
      "Chunk 13 processed in 133.52 seconds\n",
      "Chunk 14 processed in 134.54 seconds\n",
      "Chunk 15 processed in 133.71 seconds\n",
      "Chunk 16 processed in 133.15 seconds\n",
      "Chunk 17 processed in 133.37 seconds\n",
      "Chunk 18 processed in 133.21 seconds\n",
      "Chunk 19 processed in 133.57 seconds\n",
      "Chunk 20 processed in 133.78 seconds\n",
      "Chunk 21 processed in 133.36 seconds\n",
      "Chunk 22 processed in 133.32 seconds\n",
      "Chunk 23 processed in 133.81 seconds\n",
      "Chunk 24 processed in 133.76 seconds\n",
      "Chunk 25 processed in 133.11 seconds\n",
      "Chunk 26 processed in 134.43 seconds\n",
      "Chunk 27 processed in 133.86 seconds\n",
      "Chunk 28 processed in 133.63 seconds\n",
      "Chunk 29 processed in 133.79 seconds\n",
      "Chunk 30 processed in 134.15 seconds\n",
      "Chunk 31 processed in 133.62 seconds\n",
      "Chunk 32 processed in 133.47 seconds\n",
      "Chunk 33 processed in 134.17 seconds\n",
      "Chunk 34 processed in 133.70 seconds\n",
      "Chunk 35 processed in 133.65 seconds\n",
      "Chunk 36 processed in 133.35 seconds\n",
      "Chunk 37 processed in 133.56 seconds\n",
      "Chunk 38 processed in 133.62 seconds\n",
      "Chunk 39 processed in 133.39 seconds\n",
      "Chunk 40 processed in 133.86 seconds\n",
      "Chunk 41 processed in 133.67 seconds\n",
      "Chunk 42 processed in 133.96 seconds\n",
      "Chunk 43 processed in 133.72 seconds\n",
      "Chunk 44 processed in 133.70 seconds\n",
      "Chunk 45 processed in 133.66 seconds\n",
      "Chunk 46 processed in 134.16 seconds\n",
      "Chunk 47 processed in 133.83 seconds\n",
      "Chunk 48 processed in 133.51 seconds\n",
      "Chunk 49 processed in 134.54 seconds\n",
      "Chunk 50 processed in 133.57 seconds\n",
      "Chunk 51 processed in 133.92 seconds\n",
      "Chunk 52 processed in 21.78 seconds\n",
      "\n",
      "✅ All chunks processed in 6954.98 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>All_Businesses</th>\n",
       "      <th>All_Employees</th>\n",
       "      <th>Auto_B</th>\n",
       "      <th>Auto_E</th>\n",
       "      <th>Alum_B</th>\n",
       "      <th>Alum_E</th>\n",
       "      <th>Steel_B</th>\n",
       "      <th>Steel_E</th>\n",
       "      <th>Cop_B</th>\n",
       "      <th>...</th>\n",
       "      <th>325314</th>\n",
       "      <th>327120</th>\n",
       "      <th>114114</th>\n",
       "      <th>212394</th>\n",
       "      <th>324110</th>\n",
       "      <th>331317</th>\n",
       "      <th>325120</th>\n",
       "      <th>315990</th>\n",
       "      <th>334410</th>\n",
       "      <th>111120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>170</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010165</td>\n",
       "      <td>22</td>\n",
       "      <td>266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010166</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010167</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010168</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55246</th>\n",
       "      <td>62080023</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55247</th>\n",
       "      <td>62080024</td>\n",
       "      <td>11</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55248</th>\n",
       "      <td>62080025</td>\n",
       "      <td>11</td>\n",
       "      <td>356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55249</th>\n",
       "      <td>62080026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55250</th>\n",
       "      <td>62080027</td>\n",
       "      <td>13</td>\n",
       "      <td>414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55251 rows × 329 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DA  All_Businesses  All_Employees  Auto_B  Auto_E  Alum_B  \\\n",
       "0      10000000             170           1006     0.0     0.0     0.0   \n",
       "1      10010165              22            266     0.0     0.0     0.0   \n",
       "2      10010166               2              6     0.0     0.0     0.0   \n",
       "3      10010167               6             22     0.0     0.0     0.0   \n",
       "4      10010168               5             19     0.0     0.0     0.0   \n",
       "...         ...             ...            ...     ...     ...     ...   \n",
       "55246  62080023               2             10     0.0     0.0     0.0   \n",
       "55247  62080024              11            113     0.0     0.0     0.0   \n",
       "55248  62080025              11            356     0.0     0.0     0.0   \n",
       "55249  62080026               0              0     0.0     0.0     0.0   \n",
       "55250  62080027              13            414     0.0     0.0     0.0   \n",
       "\n",
       "       Alum_E  Steel_B  Steel_E  Cop_B  ...  325314  327120  114114  212394  \\\n",
       "0         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "1         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "2         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "3         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "4         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "...       ...      ...      ...    ...  ...     ...     ...     ...     ...   \n",
       "55246     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "55247     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "55248     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "55249     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "55250     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "\n",
       "       324110  331317  325120  315990  334410  111120  \n",
       "0           0       0       0       0       0       0  \n",
       "1           0       0       0       0       0       0  \n",
       "2           0       0       0       0       0       0  \n",
       "3           0       0       0       0       0       0  \n",
       "4           0       0       0       0       0       0  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "55246       0       0       0       0       0       0  \n",
       "55247       0       0       0       0       0       0  \n",
       "55248       0       0       0       0       0       0  \n",
       "55249       0       0       0       0       0       0  \n",
       "55250       0       0       0       0       0       0  \n",
       "\n",
       "[55251 rows x 329 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 1_000_000  # Start with 100k rows per chunk\n",
    "results = []  # Store aggregated results\n",
    "\n",
    "province_code = {\n",
    "    10: 'NL',\n",
    "    11: 'PEI',\n",
    "    12: 'NS',\n",
    "    13: 'NB',\n",
    "    24: 'QC',\n",
    "    35: 'ON',\n",
    "    46: 'MB',\n",
    "    47: 'SK',\n",
    "    48: 'AL',\n",
    "    59: 'BC',\n",
    "    60: 'YK',\n",
    "    61: 'NWT',\n",
    "    62: 'NU'\n",
    "}\n",
    "\n",
    "# Remove unwanted columns\n",
    "cols_to_keep = [col for col in pd.read_csv('Dec2022_Estabcounts_byDA.csv', encoding='ISO-8859-1', nrows=1).columns \n",
    "               if col != 'Without employees']\n",
    "\n",
    "# ✅ Start total timer\n",
    "total_start = time.time()\n",
    "\n",
    "# ✅ Track chunk count\n",
    "chunk_num = 0\n",
    "\n",
    "# Read in chunks\n",
    "for chunk in pd.read_csv('Dec2022_Estabcounts_byDA.csv', encoding='ISO-8859-1', chunksize=chunk_size, usecols=cols_to_keep):\n",
    "\n",
    "    chunk_num += 1\n",
    "    chunk_start = time.time()  # ✅ start chunk timer\n",
    "    \n",
    "    # Step 1: Filter unwanted rows\n",
    "    chunk = chunk[~chunk['NAICS'].isin(['Sub-total, classified', 'Unclassified', 'Total'])]\n",
    "    \n",
    "    # Step 2: Clean/transform data\n",
    "    chunk['NAICS'] = chunk['NAICS'].astype(str).str[:6]\n",
    "    chunk['Business_per_NAICS'] = chunk['Total, with employees']\n",
    "    chunk['Est_Employees'] = (\n",
    "        chunk['1-4'] * 3 +\n",
    "        chunk['5-9'] * 7 +\n",
    "        chunk['10-19'] * 15 +\n",
    "        chunk['20-49'] * 35 +\n",
    "        chunk['50-99'] * 75 +\n",
    "        chunk['100-199'] * 150 +\n",
    "        chunk['200-499'] * 350 +\n",
    "        chunk['500 +'] * 550\n",
    "    )\n",
    "    chunk['ProvinceCode'] = chunk['DisseminationAre'].astype(str).str[:2].astype(int)\n",
    "    chunk['Province'] = chunk['ProvinceCode'].map(province_code)\n",
    "\n",
    "    # Step 3: Merge with weight_naics to get weights\n",
    "    merged = chunk.merge(weight_naics, how='left', left_on='NAICS', right_on='naics')\n",
    "\n",
    "    # Step 4: Lookup province rate per row\n",
    "    merged['Rate'] = merged.apply(lambda row: row.get(f\"{row['Province']}_Rate\", 1.0), axis=1)\n",
    "    merged['Weighted_Business'] = np.ceil(merged['Business_per_NAICS'] * merged['Rate'])\n",
    "    merged['Weighted_Employees'] = np.ceil(merged['Est_Employees'] * merged['Rate'])\n",
    "\n",
    "    # Step 5: Group and aggregate\n",
    "    for da, group in merged.groupby('DisseminationAre'):\n",
    "        \n",
    "        result = {\n",
    "            'DA': da,\n",
    "            'All_Businesses': group['Business_per_NAICS'].sum(),\n",
    "            'All_Employees': group['Est_Employees'].sum(),\n",
    "            'Auto_B': group.loc[group['NAICS'].isin(auto_naics), 'Weighted_Business'].sum(),\n",
    "            'Auto_E': group.loc[group['NAICS'].isin(auto_naics), 'Weighted_Employees'].sum(),\n",
    "            'Alum_B': group.loc[group['NAICS'].isin(alum_naics), 'Weighted_Business'].sum(),\n",
    "            'Alum_E': group.loc[group['NAICS'].isin(alum_naics), 'Weighted_Employees'].sum(),\n",
    "            'Steel_B': group.loc[group['NAICS'].isin(steel_naics), 'Weighted_Business'].sum(),\n",
    "            'Steel_E': group.loc[group['NAICS'].isin(steel_naics), 'Weighted_Employees'].sum(),\n",
    "            'Cop_B': group.loc[group['NAICS'].isin(copper_naics), 'Weighted_Business'].sum(),\n",
    "            'Cop_E': group.loc[group['NAICS'].isin(copper_naics), 'Weighted_Employees'].sum(),\n",
    "            'Lum_B': group.loc[group['NAICS'].isin(lum_naics), 'Weighted_Business'].sum(),\n",
    "            'Lum_E': group.loc[group['NAICS'].isin(lum_naics), 'Weighted_Employees'].sum(),\n",
    "            'Ene_B': group.loc[group['NAICS'].isin(ene_naics), 'Weighted_Business'].sum(),\n",
    "            'Ene_E': group.loc[group['NAICS'].isin(ene_naics), 'Weighted_Employees'].sum(),\n",
    "            'CUSMA_B': group.loc[group['NAICS'].isin(noncusma_naics), 'Weighted_Business'].sum(),\n",
    "            'CUSMA_E': group.loc[group['NAICS'].isin(noncusma_naics), 'Weighted_Employees'].sum(),\n",
    "            'Total_B': group.loc[group['NAICS'].isin(total_naics), 'Weighted_Business'].sum(),\n",
    "            'Total_E': group.loc[group['NAICS'].isin(total_naics), 'Weighted_Employees'].sum()\n",
    "        }\n",
    "\n",
    "        # Add per-NAICS Est_Employees values\n",
    "        for naics in total_naics:\n",
    "            result[naics] = group.loc[group['NAICS'] == naics, 'Est_Employees'].sum()\n",
    "\n",
    "        results.append(result)\n",
    "        \n",
    "    # ✅ End chunk timer\n",
    "    chunk_time = time.time() - chunk_start\n",
    "    print(f\"Chunk {chunk_num} processed in {chunk_time:.2f} seconds\")\n",
    "\n",
    "# ✅ End total timer\n",
    "total_time = time.time() - total_start\n",
    "print(f\"\\n✅ All chunks processed in {total_time:.2f} seconds.\")\n",
    "\n",
    "# Combine all chunk results\n",
    "business = pd.DataFrame(results).groupby('DA', as_index=False).sum()\n",
    "business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba810d-31fa-42f3-8fc0-6dffeecbc965",
   "metadata": {},
   "source": [
    "# STEP 6: Regrouping filtered data into ADAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35bc7622-0cca-43fb-98e0-b927d6e91535",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = gpd.read_file('lda_000b21a_e.shp')\n",
    "da ['DA'] = da ['DAUID']\n",
    "da ['DADGUID'] = da ['DGUID']\n",
    "da = da[['DA', 'DADGUID']]\n",
    "\n",
    "ada = gpd.read_file('lada000b21a_e.shp')\n",
    "adac = ada.copy()\n",
    "adac ['ADADGUID'] = adac ['DGUID']\n",
    "adac = adac[['ADADGUID', 'geometry']]\n",
    "\n",
    "relation = pd.read_csv('ada_da_relation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3692e0e7-199d-40e9-84f8-aca6d38fdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_relation = da.merge(relation, on='DADGUID', how='left')\n",
    "full_relation = da_relation.merge(adac, on='ADADGUID', how='left')\n",
    "full_relation['DA'] = pd.to_numeric(full_relation['DA'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad19f64e-2d38-4e91-9a8e-477e464ebc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3982846873.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  business_grouped = business_merged.groupby('ADADGUID', as_index=False).agg(**agg_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>All_Businesses</th>\n",
       "      <th>All_Employees</th>\n",
       "      <th>Auto_B</th>\n",
       "      <th>Auto_E</th>\n",
       "      <th>Alum_B</th>\n",
       "      <th>Alum_E</th>\n",
       "      <th>Steel_B</th>\n",
       "      <th>Steel_E</th>\n",
       "      <th>Cop_B</th>\n",
       "      <th>...</th>\n",
       "      <th>325314</th>\n",
       "      <th>327120</th>\n",
       "      <th>114114</th>\n",
       "      <th>212394</th>\n",
       "      <th>324110</th>\n",
       "      <th>331317</th>\n",
       "      <th>325120</th>\n",
       "      <th>315990</th>\n",
       "      <th>334410</th>\n",
       "      <th>111120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>219</td>\n",
       "      <td>2910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>66</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>288</td>\n",
       "      <td>4186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>438</td>\n",
       "      <td>9064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>203</td>\n",
       "      <td>1441</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>11</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>13</td>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>8</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  All_Businesses  All_Employees  Auto_B  Auto_E  \\\n",
       "0     2021S051610010001             219           2910       0       0   \n",
       "1     2021S051610010002              66            394       0       0   \n",
       "2     2021S051610010003             288           4186       0       0   \n",
       "3     2021S051610010004             438           9064       0       0   \n",
       "4     2021S051610010005             203           1441       2       5   \n",
       "...                 ...             ...            ...     ...     ...   \n",
       "5428  2021S051662080004              11            356       0       0   \n",
       "5429  2021S051662080005              13            414       0       0   \n",
       "5430  2021S051662080006               8            295       0       0   \n",
       "5431  2021S051662080007               0              0       0       0   \n",
       "5432  2021S051662080008               0              0       0       0   \n",
       "\n",
       "      Alum_B  Alum_E  Steel_B  Steel_E  Cop_B  ...  325314  327120  114114  \\\n",
       "0          1       1        1        1      0  ...       0       0      10   \n",
       "1          0       0        0        0      0  ...       0       0       0   \n",
       "2          1       1        1        1      0  ...       0       0       0   \n",
       "3          1       1        1        1      1  ...       0       0       0   \n",
       "4          1       3        1        3      0  ...       0       0       0   \n",
       "...      ...     ...      ...      ...    ...  ...     ...     ...     ...   \n",
       "5428       0       0        0        0      0  ...       0       0       0   \n",
       "5429       0       0        0        0      0  ...       0       0       0   \n",
       "5430       0       0        0        0      0  ...       0       0       0   \n",
       "5431       0       0        0        0      0  ...       0       0       0   \n",
       "5432       0       0        0        0      0  ...       0       0       0   \n",
       "\n",
       "      212394  324110  331317  325120  315990  334410 111120  \n",
       "0          0       0       0       0       0       0      0  \n",
       "1          0       0       0       0       0       0      0  \n",
       "2          0       0       0       0       0       0      0  \n",
       "3          0       0       0       0       0       0      0  \n",
       "4          0       0       0       0       0       0      0  \n",
       "...      ...     ...     ...     ...     ...     ...    ...  \n",
       "5428       0       0       0       0       0       0      0  \n",
       "5429       0       0       0       0       0       0      0  \n",
       "5430       0       0       0       0       0       0      0  \n",
       "5431       0       0       0       0       0       0      0  \n",
       "5432       0       0       0       0       0       0      0  \n",
       "\n",
       "[5433 rows x 330 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_merged =(\n",
    "    business.merge(full_relation, on='DA', how='right')\n",
    "    .fillna(0)\n",
    "    .astype({col: 'int64' for col in business.columns if col != 'DA'})\n",
    ") \n",
    "\n",
    "# Group by ADADGUID and aggregate\n",
    "agg_dict = {\n",
    "    'All_Businesses': ('All_Businesses', 'sum'),\n",
    "    'All_Employees': ('All_Employees', 'sum'),\n",
    "    'Auto_B': ('Auto_B', 'sum'),\n",
    "    'Auto_E': ('Auto_E', 'sum'),\n",
    "    'Alum_B': ('Alum_B', 'sum'),\n",
    "    'Alum_E': ('Alum_E', 'sum'),\n",
    "    'Steel_B': ('Steel_B', 'sum'),\n",
    "    'Steel_E': ('Steel_E', 'sum'),\n",
    "    'Cop_B': ('Cop_B', 'sum'),\n",
    "    'Cop_E': ('Cop_E', 'sum'),\n",
    "    'Lum_B': ('Lum_B', 'sum'),\n",
    "    'Lum_E': ('Lum_E', 'sum'),\n",
    "    'Ene_B': ('Ene_B', 'sum'),\n",
    "    'Ene_E': ('Ene_E', 'sum'),\n",
    "    'CUSMA_B': ('CUSMA_B', 'sum'),\n",
    "    'CUSMA_E': ('CUSMA_E', 'sum'),\n",
    "    'Total_B': ('Total_B', 'sum'),\n",
    "    'Total_E': ('Total_E', 'sum'),\n",
    "    'geometry': ('geometry', 'first')\n",
    "}\n",
    "\n",
    "# Add dynamic aggregation rules for each NAICS code\n",
    "for naics in total_naics:\n",
    "    agg_dict[naics] = (naics, 'sum')\n",
    "\n",
    "# Perform grouped aggregation\n",
    "business_grouped = business_merged.groupby('ADADGUID', as_index=False).agg(**agg_dict)\n",
    "\n",
    "business_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52531033-7f4b-4acf-86a8-14dfc866bb3d",
   "metadata": {},
   "source": [
    "# STEP 7: Processing it into Centroids for Counts and Choropleth for Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d202b-3efd-4e51-ad51-67d4cc727ee2",
   "metadata": {},
   "source": [
    "Since the earlier table shows the *weighted* numbers of directly exposed businesses and employees (by work location) together with *total* number of employees (by work location) for each affected NAICS code, the former is separated from the latter. The former needs to be processed into separate GDFs for centroids (to show counts) and choropleths (to show percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ba63611-0a2b-4b5b-ab39-a7401b9f15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_cols = [\n",
    "    'All_Businesses', 'All_Employees',\n",
    "    'Auto_B', 'Auto_E', 'Alum_B', 'Alum_E',\n",
    "    'Steel_B', 'Steel_E', 'Cop_B', 'Cop_E',\n",
    "    'Lum_B', 'Lum_E', 'Ene_B', 'Ene_E', \n",
    "    'CUSMA_B', 'CUSMA_E', 'Total_B', 'Total_E', \n",
    "    'geometry'\n",
    "]\n",
    "\n",
    "business_filter = business_grouped[['ADADGUID'] + [col for col in business_grouped.columns if col in excluded_cols]]\n",
    "\n",
    "business_census = business_grouped[[col for col in business_grouped.columns if col not in excluded_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b57b36a2-b77e-4eff-8a20-be2252a41ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Auto_B</th>\n",
       "      <th>Auto_E</th>\n",
       "      <th>Alum_B</th>\n",
       "      <th>Alum_E</th>\n",
       "      <th>Steel_B</th>\n",
       "      <th>Steel_E</th>\n",
       "      <th>Cop_B</th>\n",
       "      <th>Cop_E</th>\n",
       "      <th>Lum_B</th>\n",
       "      <th>Lum_E</th>\n",
       "      <th>Ene_B</th>\n",
       "      <th>Ene_E</th>\n",
       "      <th>CUSMA_B</th>\n",
       "      <th>CUSMA_E</th>\n",
       "      <th>Total_B</th>\n",
       "      <th>Total_E</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>791</td>\n",
       "      <td>16</td>\n",
       "      <td>791</td>\n",
       "      <td>POINT (8927316.642 2156398.591)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>POINT (8966678.602 2164982.461)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>POINT (8934606.046 2144277.889)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>POINT (8976138.327 2157799.904)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>POINT (8970965.684 2157632.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (5259010.983 3653721.631)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (6041286.124 3573109.546)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (6281761.356 3557612.071)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (5550011.303 3546406.473)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (5515075.425 3459918.304)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  Auto_B  Auto_E  Alum_B  Alum_E  Steel_B  Steel_E  \\\n",
       "0     2021S051610010001       0       0       1       1        1        1   \n",
       "1     2021S051610010002       0       0       0       0        0        0   \n",
       "2     2021S051610010003       0       0       1       1        1        1   \n",
       "3     2021S051610010004       0       0       1       1        1        1   \n",
       "4     2021S051610010005       2       5       1       3        1        3   \n",
       "...                 ...     ...     ...     ...     ...      ...      ...   \n",
       "5428  2021S051662080004       0       0       0       0        0        0   \n",
       "5429  2021S051662080005       0       0       0       0        0        0   \n",
       "5430  2021S051662080006       0       0       0       0        0        0   \n",
       "5431  2021S051662080007       0       0       0       0        0        0   \n",
       "5432  2021S051662080008       0       0       0       0        0        0   \n",
       "\n",
       "      Cop_B  Cop_E  Lum_B  Lum_E  Ene_B  Ene_E  CUSMA_B  CUSMA_E  Total_B  \\\n",
       "0         0      0      2      6      0      0       16      791       16   \n",
       "1         0      0      0      0      0      0        2       10        2   \n",
       "2         0      0      4     37      0      0        9       49        9   \n",
       "3         1      1      0      0      2     25        7       67        7   \n",
       "4         0      0      0      0      0      0        5       29        5   \n",
       "...     ...    ...    ...    ...    ...    ...      ...      ...      ...   \n",
       "5428      0      0      0      0      0      0        0        0        0   \n",
       "5429      0      0      0      0      0      0        0        0        0   \n",
       "5430      0      0      0      0      0      0        0        0        0   \n",
       "5431      0      0      0      0      0      0        0        0        0   \n",
       "5432      0      0      0      0      0      0        0        0        0   \n",
       "\n",
       "      Total_E                         geometry  \n",
       "0         791  POINT (8927316.642 2156398.591)  \n",
       "1          10  POINT (8966678.602 2164982.461)  \n",
       "2          49  POINT (8934606.046 2144277.889)  \n",
       "3          67  POINT (8976138.327 2157799.904)  \n",
       "4          29    POINT (8970965.684 2157632.7)  \n",
       "...       ...                              ...  \n",
       "5428        0  POINT (5259010.983 3653721.631)  \n",
       "5429        0  POINT (6041286.124 3573109.546)  \n",
       "5430        0  POINT (6281761.356 3557612.071)  \n",
       "5431        0  POINT (5550011.303 3546406.473)  \n",
       "5432        0  POINT (5515075.425 3459918.304)  \n",
       "\n",
       "[5433 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to GeoDataFrame\n",
    "cent_gdf = gpd.GeoDataFrame(business_filter, geometry='geometry', crs = 'EPSG:3347')\n",
    "\n",
    "# Set a point within each polygon\n",
    "cent_gdf = cent_gdf.drop(columns=['All_Businesses', 'All_Employees'])\n",
    "cent_gdf['geometry'] = cent_gdf.geometry.representative_point()\n",
    "cent_gdf.set_geometry('geometry', inplace=True)\n",
    "cent_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f018d8-0a4d-4ee3-ac34-aefbf0a1fc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>All_Businesses</th>\n",
       "      <th>All_Employees</th>\n",
       "      <th>Auto_1</th>\n",
       "      <th>Alum_1</th>\n",
       "      <th>Steel_1</th>\n",
       "      <th>Cop_1</th>\n",
       "      <th>Lum_1</th>\n",
       "      <th>Ene_1</th>\n",
       "      <th>CUSMA_1</th>\n",
       "      <th>Total_1</th>\n",
       "      <th>Auto_2</th>\n",
       "      <th>Alum_2</th>\n",
       "      <th>Steel_2</th>\n",
       "      <th>Cop_2</th>\n",
       "      <th>Lum_2</th>\n",
       "      <th>Ene_2</th>\n",
       "      <th>CUSMA_2</th>\n",
       "      <th>Total_2</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>219</td>\n",
       "      <td>2910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271821</td>\n",
       "      <td>0.271821</td>\n",
       "      <td>MULTIPOLYGON (((8921559.157 2130255.903, 89215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>66</td>\n",
       "      <td>394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>POLYGON ((8959571.943 2171799.486, 8959576.689...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>288</td>\n",
       "      <td>4186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>MULTIPOLYGON (((8938088.457 2157739.16, 893808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>438</td>\n",
       "      <td>9064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>POLYGON ((8976008.48 2163749.357, 8976015.274 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>203</td>\n",
       "      <td>1441</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.00347</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>POLYGON ((8969716.249 2163377.051, 8969785.883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>11</td>\n",
       "      <td>356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((5263454.031 3662224.177, 52634...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>13</td>\n",
       "      <td>414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((6043125.089 3568426.163, 60431...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>8</td>\n",
       "      <td>295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((6280121.289 3558103.571, 62801...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((5544792.883 3549525.897, 55447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((5516884.22 3462631.751, 551687...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  All_Businesses  All_Employees    Auto_1    Alum_1  \\\n",
       "0     2021S051610010001             219           2910  0.000000  0.004566   \n",
       "1     2021S051610010002              66            394  0.000000  0.000000   \n",
       "2     2021S051610010003             288           4186  0.000000  0.003472   \n",
       "3     2021S051610010004             438           9064  0.000000  0.002283   \n",
       "4     2021S051610010005             203           1441  0.009852  0.004926   \n",
       "...                 ...             ...            ...       ...       ...   \n",
       "5428  2021S051662080004              11            356  0.000000  0.000000   \n",
       "5429  2021S051662080005              13            414  0.000000  0.000000   \n",
       "5430  2021S051662080006               8            295  0.000000  0.000000   \n",
       "5431  2021S051662080007               0              0  0.000000  0.000000   \n",
       "5432  2021S051662080008               0              0  0.000000  0.000000   \n",
       "\n",
       "       Steel_1     Cop_1     Lum_1     Ene_1   CUSMA_1   Total_1   Auto_2  \\\n",
       "0     0.004566  0.000000  0.009132  0.000000  0.073059  0.073059  0.00000   \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.030303  0.030303  0.00000   \n",
       "2     0.003472  0.000000  0.013889  0.000000  0.031250  0.031250  0.00000   \n",
       "3     0.002283  0.002283  0.000000  0.004566  0.015982  0.015982  0.00000   \n",
       "4     0.004926  0.000000  0.000000  0.000000  0.024631  0.024631  0.00347   \n",
       "...        ...       ...       ...       ...       ...       ...      ...   \n",
       "5428  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "5429  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "5430  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "5431  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "5432  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "\n",
       "        Alum_2   Steel_2    Cop_2     Lum_2     Ene_2   CUSMA_2   Total_2  \\\n",
       "0     0.000344  0.000344  0.00000  0.002062  0.000000  0.271821  0.271821   \n",
       "1     0.000000  0.000000  0.00000  0.000000  0.000000  0.025381  0.025381   \n",
       "2     0.000239  0.000239  0.00000  0.008839  0.000000  0.011706  0.011706   \n",
       "3     0.000110  0.000110  0.00011  0.000000  0.002758  0.007392  0.007392   \n",
       "4     0.002082  0.002082  0.00000  0.000000  0.000000  0.020125  0.020125   \n",
       "...        ...       ...      ...       ...       ...       ...       ...   \n",
       "5428  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "5429  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "5430  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "5431  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "5432  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                               geometry  \n",
       "0     MULTIPOLYGON (((8921559.157 2130255.903, 89215...  \n",
       "1     POLYGON ((8959571.943 2171799.486, 8959576.689...  \n",
       "2     MULTIPOLYGON (((8938088.457 2157739.16, 893808...  \n",
       "3     POLYGON ((8976008.48 2163749.357, 8976015.274 ...  \n",
       "4     POLYGON ((8969716.249 2163377.051, 8969785.883...  \n",
       "...                                                 ...  \n",
       "5428  MULTIPOLYGON (((5263454.031 3662224.177, 52634...  \n",
       "5429  MULTIPOLYGON (((6043125.089 3568426.163, 60431...  \n",
       "5430  MULTIPOLYGON (((6280121.289 3558103.571, 62801...  \n",
       "5431  MULTIPOLYGON (((5544792.883 3549525.897, 55447...  \n",
       "5432  MULTIPOLYGON (((5516884.22 3462631.751, 551687...  \n",
       "\n",
       "[5433 rows x 20 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choro_cols = business_filter.copy()\n",
    "\n",
    "tars = ['Auto', 'Alum', 'Steel', 'Cop', 'Lum', 'Ene', 'CUSMA', 'Total']\n",
    "\n",
    "for tar in tars:\n",
    "    tar_1 = f'{tar}_1'\n",
    "    tar_2 = f'{tar}_2'\n",
    "\n",
    "    choro_cols[tar_1] = (\n",
    "        choro_cols[f'{tar}_B']/choro_cols['All_Businesses']\n",
    "    )\n",
    "\n",
    "    choro_cols[tar_2] = (\n",
    "        choro_cols[f'{tar}_E']/choro_cols['All_Employees']\n",
    "    )\n",
    "\n",
    "choro_cols = choro_cols[['ADADGUID', 'All_Businesses', 'All_Employees'] + [f'{tar}_1' for tar in tars] + [f'{tar}_2' for tar in tars] + ['geometry']]\n",
    "choro_cols = choro_cols.fillna(0)\n",
    "\n",
    "choro_gdf = gpd.GeoDataFrame(choro_cols, geometry = 'geometry', crs = 'EPSG:3347')\n",
    "choro_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7802b6-9d94-4938-b399-e8b54e6de279",
   "metadata": {},
   "source": [
    "# STEP 8: Generating Weight of Directly Exposed Jobs to Total Accessible Jobs in Each Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5543a3-382b-41fb-84b5-890700d7b60c",
   "metadata": {},
   "source": [
    "It is likely that while employees live close to their workplace, they do not live in the same ADA as they work in.  \n",
    "  \n",
    "StatsCan Census 2021 data shows a huge drop in the number of Canadians who travel more than 15km to their work vis-a-vis those who travel less than that distance to work.  \n",
    "  \n",
    "Thus, this cell creates a dictionary where for each ADA, it lists down, including itself, the ADA IDs within a 15km buffer around it (for small ADAs) or ADA IDs that are adjacent to it (for large ADAs). Small ADAs are defined as ADAs with an area less than (15km)^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7087f7bf-537e-4017-9640-0a05f178b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▌                                                                           | 1/11 [00:24<04:02, 24.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0-500 processed in 0:00:24.280664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████                                                                    | 2/11 [00:26<01:40, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 500-1000 processed in 0:00:01.918972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████▋                                                            | 3/11 [00:28<00:57,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1000-1500 processed in 0:00:02.358576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▏                                                    | 4/11 [00:52<01:35, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1500-2000 processed in 0:00:23.606894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▋                                             | 5/11 [00:53<00:55,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2000-2500 processed in 0:00:01.574130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████▎                                     | 6/11 [01:33<01:37, 19.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2500-3000 processed in 0:00:39.384200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████▊                              | 7/11 [01:43<01:05, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3000-3500 processed in 0:00:09.912982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [01:44<00:34, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3500-4000 processed in 0:00:01.333966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [01:45<00:16,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4000-4500 processed in 0:00:01.297525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 10/11 [01:51<00:07,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4500-5000 processed in 0:00:05.797197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [03:45<00:00, 20.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 5000-5433 processed in 0:01:53.765980\n",
      "\n",
      "Total time taken: 0:03:45.293965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Copy from earlier ADA shapefile and ensure it's in projected CRS (EPSG:3347)\n",
    "adas = ada.to_crs(\"EPSG:3347\")\n",
    "\n",
    "# Create a column to mark if ADA is \"small\" (<= 706 km2)\n",
    "adas['is_small'] = adas['LANDAREA'] <= 706\n",
    "\n",
    "# Build spatial index once\n",
    "adas_sindex = adas.sindex\n",
    "\n",
    "# Simplify geometries early to reduce memory use\n",
    "adas['geometry'] = adas['geometry'].simplify(100)\n",
    "\n",
    "# Prepare empty dictionary\n",
    "ada_neighbors = {}\n",
    "\n",
    "# Process in chunks to avoid RAM overload\n",
    "chunk_size = 500\n",
    "n = len(adas)\n",
    "\n",
    "# Track overall time\n",
    "start_time = time.time()\n",
    "\n",
    "for start in tqdm(range(0, n, chunk_size)):\n",
    "    chunk_start_time = time.time()\n",
    "    end = min(start + chunk_size, n)\n",
    "    chunk = adas.iloc[start:end].copy()\n",
    "\n",
    "    for idx, row in chunk.iterrows():\n",
    "        ada_uid = row['DGUID']\n",
    "        geom = row['geometry']\n",
    "        is_small = row['is_small']\n",
    "\n",
    "        if is_small:\n",
    "            buffer_geom = geom.buffer(15000)\n",
    "            possible_matches_index = list(adas_sindex.intersection(buffer_geom.bounds))\n",
    "            possible_matches = adas.iloc[possible_matches_index]\n",
    "            matches = possible_matches[possible_matches.geometry.intersects(buffer_geom)]\n",
    "        else:\n",
    "            possible_matches_index = list(adas_sindex.intersection(geom.bounds))\n",
    "            possible_matches = adas.iloc[possible_matches_index]\n",
    "            matches = possible_matches[possible_matches.geometry.touches(geom) | (possible_matches['DGUID'] == ada_uid)]\n",
    "\n",
    "        ada_neighbors[ada_uid] = matches['DGUID'].tolist()\n",
    "\n",
    "    del chunk\n",
    "    gc.collect()\n",
    "\n",
    "    # Print chunk timing\n",
    "    chunk_elapsed = time.time() - chunk_start_time\n",
    "    print(f\"Chunk {start}-{end} processed in {timedelta(seconds=chunk_elapsed)}\")\n",
    "\n",
    "# Overall timing\n",
    "total_elapsed = time.time() - start_time\n",
    "print(f\"\\nTotal time taken: {timedelta(seconds=total_elapsed)}\")\n",
    "\n",
    "# Optionally save the dictionary to disk\n",
    "with open(\"ada_neighbors.json\", \"w\") as f:\n",
    "    json.dump(ada_neighbors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841738d-8e78-40e3-a8b7-a2f120eea5f7",
   "metadata": {},
   "source": [
    "The dictionary is then used in conjunction with the *total* count of employees (by work location), as separated in Cell 13 above, to find out the likely number of jobs of each 6-digit NAICS, and total number of jobs, that are 'accessible' from each ADA --> going by the assumption of travel distance made by Canadians to go to work from Census 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89928d72-34aa-4064-9f8d-abcc4df05247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5433/5433 [00:04<00:00, 1090.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'ADADGUID' is the index for fast lookup\n",
    "business_census_indexed = business_census.set_index('ADADGUID')\n",
    "\n",
    "# Prepare list to collect results\n",
    "aggregated_results = []\n",
    "\n",
    "# Loop through ADA + its neighbors\n",
    "for ada_id, neighbor_list in tqdm(ada_neighbors.items()):\n",
    "    # Filter business_census rows for all neighbors\n",
    "    rows = business_census_indexed.loc[business_census_indexed.index.intersection(neighbor_list)]\n",
    "    \n",
    "    # Sum across all rows (by column)\n",
    "    summed = rows.sum()\n",
    "    \n",
    "    # Store result with ADA ID\n",
    "    result = summed.to_dict()\n",
    "    result['ADADGUID'] = ada_id\n",
    "    \n",
    "    aggregated_results.append(result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "jobs = pd.DataFrame(aggregated_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b623b-bad5-4aaf-a96d-f274d89c3eb5",
   "metadata": {},
   "source": [
    "This is to find out the rate of directly exposed jobs (6-digit NAICS) to total jobs in each industry (1-digit NAICS jobs) that are accessible from each ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5315dd5f-23f8-4972-aded-e58033b28780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>333920_R</th>\n",
       "      <th>327390_R</th>\n",
       "      <th>332329_R</th>\n",
       "      <th>326111_R</th>\n",
       "      <th>111419_R</th>\n",
       "      <th>312220_R</th>\n",
       "      <th>321991_R</th>\n",
       "      <th>325910_R</th>\n",
       "      <th>327990_R</th>\n",
       "      <th>...</th>\n",
       "      <th>325314_R</th>\n",
       "      <th>327120_R</th>\n",
       "      <th>114114_R</th>\n",
       "      <th>212394_R</th>\n",
       "      <th>324110_R</th>\n",
       "      <th>331317_R</th>\n",
       "      <th>325120_R</th>\n",
       "      <th>315990_R</th>\n",
       "      <th>334410_R</th>\n",
       "      <th>111120_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  333920_R  327390_R  332329_R  326111_R  111419_R  \\\n",
       "0     2021S051610010001  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "1     2021S051610010002  0.005297       0.0  0.002472  0.000000  0.004127   \n",
       "2     2021S051610010003  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "3     2021S051610010004  0.003981       0.0  0.001858  0.003981  0.003713   \n",
       "4     2021S051610010005  0.003981       0.0  0.001858  0.003981  0.003713   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "5428  2021S051662080004  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "5429  2021S051662080005  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "5430  2021S051662080006  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "5431  2021S051662080007  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "5432  2021S051662080008  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "      312220_R  321991_R  325910_R  327990_R  ...  325314_R  327120_R  \\\n",
       "0          0.0       0.0       0.0  0.000000  ...       0.0       0.0   \n",
       "1          0.0       0.0       0.0  0.002472  ...       0.0       0.0   \n",
       "2          0.0       0.0       0.0  0.000000  ...       0.0       0.0   \n",
       "3          0.0       0.0       0.0  0.001858  ...       0.0       0.0   \n",
       "4          0.0       0.0       0.0  0.001858  ...       0.0       0.0   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "5428       0.0       0.0       0.0  0.000000  ...       0.0       0.0   \n",
       "5429       0.0       0.0       0.0  0.000000  ...       0.0       0.0   \n",
       "5430       0.0       0.0       0.0  0.000000  ...       0.0       0.0   \n",
       "5431       0.0       0.0       0.0  0.000000  ...       0.0       0.0   \n",
       "5432       0.0       0.0       0.0  0.000000  ...       0.0       0.0   \n",
       "\n",
       "      114114_R  212394_R  324110_R  331317_R  325120_R  315990_R  334410_R  \\\n",
       "0     0.059524       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "1     0.000000       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "2     0.025974       0.0  0.160303       0.0   0.00204       0.0       0.0   \n",
       "3     0.000000       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "4     0.000000       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5428  0.000000       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "5429  0.000000       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "5430  0.000000       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "5431  0.000000       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "5432  0.000000       0.0  0.000000       0.0   0.00000       0.0       0.0   \n",
       "\n",
       "      111120_R  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "5428       0.0  \n",
       "5429       0.0  \n",
       "5430       0.0  \n",
       "5431       0.0  \n",
       "5432       0.0  \n",
       "\n",
       "[5433 rows x 311 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_rate = jobs.copy()\n",
    "\n",
    "cola = [col for col in jobs.columns if col != 'ADADGUID']\n",
    "\n",
    "# Calculate summed groups by first digit of column name\n",
    "jobs_rate['Sum1'] = jobs_rate[[col for col in cola if col.startswith('1')]].sum(axis=1)\n",
    "jobs_rate['Sum2'] = jobs_rate[[col for col in cola if col.startswith('2')]].sum(axis=1)\n",
    "jobs_rate['Sum3'] = jobs_rate[[col for col in cola if col.startswith('3')]].sum(axis=1)\n",
    "\n",
    "# Compute share per column\n",
    "for col in cola:\n",
    "    col_rate = f'{col}_R'\n",
    "    if col.startswith('1'):\n",
    "        jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
    "    elif col.startswith('2'):\n",
    "        jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
    "    elif col.startswith('3'):\n",
    "        jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
    "    else:\n",
    "        jobs_rate[col_rate] = 0  # fallback in case of unexpected prefix\n",
    "\n",
    "# Final filtered DataFrame: only ADADGUID and the *_R columns\n",
    "jobs_rate = jobs_rate[['ADADGUID'] + [f'{col}_R' for col in cola]]\n",
    "\n",
    "jobs_rate = jobs_rate.fillna(0)\n",
    "\n",
    "jobs_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37308b-3570-44a3-a6de-d493c61782e3",
   "metadata": {},
   "source": [
    "# STEP 9: Applying Jobs Weight to Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e93621-6a33-436c-be5c-7344ca76e3de",
   "metadata": {},
   "source": [
    "Census 2021 Data reports residents' occupational NAICS code at the two-digit level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb473b54-6e12-4e46-bdd2-d98a29a8cbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CHARACTERISTIC_NAME</th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>ProvinceCode</th>\n",
       "      <th>Province</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>To</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>10</td>\n",
       "      <td>NL</td>\n",
       "      <td>455.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>3715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>10</td>\n",
       "      <td>NL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>10</td>\n",
       "      <td>NL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>4530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>10</td>\n",
       "      <td>NL</td>\n",
       "      <td>20.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>10</td>\n",
       "      <td>NL</td>\n",
       "      <td>35.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>2021S051662080002</td>\n",
       "      <td>62</td>\n",
       "      <td>NU</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>2021S051662080003</td>\n",
       "      <td>62</td>\n",
       "      <td>NU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>62</td>\n",
       "      <td>NU</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>62</td>\n",
       "      <td>NU</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>62</td>\n",
       "      <td>NU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4962 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "CHARACTERISTIC_NAME           ADADGUID  ProvinceCode Province     11     21  \\\n",
       "0                    2021S051610010001            10       NL  455.0  120.0   \n",
       "1                    2021S051610010002            10       NL   50.0   70.0   \n",
       "2                    2021S051610010003            10       NL  160.0  100.0   \n",
       "3                    2021S051610010004            10       NL   20.0  170.0   \n",
       "4                    2021S051610010005            10       NL   35.0  215.0   \n",
       "...                                ...           ...      ...    ...    ...   \n",
       "4957                 2021S051662080002            62       NU   10.0   15.0   \n",
       "4958                 2021S051662080003            62       NU    0.0    0.0   \n",
       "4959                 2021S051662080004            62       NU   10.0    0.0   \n",
       "4960                 2021S051662080005            62       NU   10.0   10.0   \n",
       "4961                 2021S051662080006            62       NU    0.0    0.0   \n",
       "\n",
       "CHARACTERISTIC_NAME     31      To  \n",
       "0                    665.0  3715.0  \n",
       "1                     60.0  2120.0  \n",
       "2                    310.0  4530.0  \n",
       "3                    130.0  5145.0  \n",
       "4                    130.0  5190.0  \n",
       "...                    ...     ...  \n",
       "4957                  10.0   860.0  \n",
       "4958                   0.0   210.0  \n",
       "4959                   0.0   510.0  \n",
       "4960                   0.0   465.0  \n",
       "4961                   0.0   280.0  \n",
       "\n",
       "[4962 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census = pd.read_csv('98-401-X2021012_English_CSV_data.csv', encoding='latin1')\n",
    "\n",
    "census = census[census['CHARACTERISTIC_ID'].isin([2259, 2262, 2263, 2266])] # Only taking the relevant 2-digit NAICS codes from Census 2021 data\n",
    "\n",
    "census['ADADGUID'] = census['DGUID']\n",
    "\n",
    "census['ProvinceCode'] = census['ADADGUID'].str[9:11].astype(int)\n",
    "\n",
    "census['Province'] = census['ProvinceCode'].map(province_code)\n",
    "\n",
    "census['CHARACTERISTIC_NAME'] = (\n",
    "    census['CHARACTERISTIC_NAME']\n",
    "    .str.replace(' ', '', regex=False)\n",
    "    .str[:2]\n",
    ")\n",
    "\n",
    "census = census[['ADADGUID', 'ProvinceCode', 'Province', 'CHARACTERISTIC_NAME', 'C1_COUNT_TOTAL']]\n",
    "\n",
    "census_pivot = census.pivot_table(\n",
    "    index=['ADADGUID', 'ProvinceCode', 'Province'],\n",
    "    columns='CHARACTERISTIC_NAME',\n",
    "    values='C1_COUNT_TOTAL',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "census_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1defe9-ea10-4d5b-86f7-c9abf0cbf776",
   "metadata": {},
   "source": [
    "Thus the weights from Step 8 is used to estimate how many employees (by primary residence) are working in industries directly exposed to tariffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "368f4477-8730-4609-ba8d-4e4f4ab48640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\2488107975.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs['Sum'] = adjusted_jobs.drop(columns=['ADADGUID', 'Province', 'To']).sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Province</th>\n",
       "      <th>To</th>\n",
       "      <th>333920</th>\n",
       "      <th>327390</th>\n",
       "      <th>332329</th>\n",
       "      <th>326111</th>\n",
       "      <th>111419</th>\n",
       "      <th>312220</th>\n",
       "      <th>321991</th>\n",
       "      <th>...</th>\n",
       "      <th>327120</th>\n",
       "      <th>114114</th>\n",
       "      <th>212394</th>\n",
       "      <th>324110</th>\n",
       "      <th>331317</th>\n",
       "      <th>325120</th>\n",
       "      <th>315990</th>\n",
       "      <th>334410</th>\n",
       "      <th>111120</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>NL</td>\n",
       "      <td>3715.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>NL</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>NL</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>NL</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>NL</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>NU</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>NU</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>NU</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>NU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>NU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID Province      To  333920  327390  332329  326111  \\\n",
       "0     2021S051610010001       NL  3715.0     0.0     0.0     0.0     0.0   \n",
       "1     2021S051610010002       NL  2120.0     1.0     0.0     1.0     0.0   \n",
       "2     2021S051610010003       NL  4530.0     0.0     0.0     0.0     0.0   \n",
       "3     2021S051610010004       NL  5145.0     1.0     0.0     1.0     1.0   \n",
       "4     2021S051610010005       NL  5190.0     1.0     0.0     1.0     1.0   \n",
       "...                 ...      ...     ...     ...     ...     ...     ...   \n",
       "5428  2021S051662080004       NU   510.0     0.0     0.0     0.0     0.0   \n",
       "5429  2021S051662080005       NU   465.0     0.0     0.0     0.0     0.0   \n",
       "5430  2021S051662080006       NU   280.0     0.0     0.0     0.0     0.0   \n",
       "5431  2021S051662080007       NU     0.0     0.0     0.0     0.0     0.0   \n",
       "5432  2021S051662080008       NU     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      111419  312220  321991  ...  327120  114114  212394  324110  331317  \\\n",
       "0        0.0     0.0     0.0  ...     0.0    28.0     0.0     0.0     0.0   \n",
       "1        1.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "2        0.0     0.0     0.0  ...     0.0     5.0     0.0    50.0     0.0   \n",
       "3        1.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "4        1.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "...      ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "5428     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5429     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5430     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5431     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5432     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      325120  315990  334410  111120     Sum  \n",
       "0        0.0     0.0     0.0     0.0  1129.0  \n",
       "1        0.0     0.0     0.0     0.0   225.0  \n",
       "2        1.0     0.0     0.0     0.0   590.0  \n",
       "3        0.0     0.0     0.0     0.0   379.0  \n",
       "4        0.0     0.0     0.0     0.0   437.0  \n",
       "...      ...     ...     ...     ...     ...  \n",
       "5428     0.0     0.0     0.0     0.0     0.0  \n",
       "5429     0.0     0.0     0.0     0.0     0.0  \n",
       "5430     0.0     0.0     0.0     0.0     0.0  \n",
       "5431     0.0     0.0     0.0     0.0     0.0  \n",
       "5432     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5433 rows x 314 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge on ADADGUID to align both datasets\n",
    "merged = census_pivot.merge(jobs_rate, on='ADADGUID', how='right')  # or 'left' if census is base\n",
    "\n",
    "# Start building the adjusted DataFrame\n",
    "adjusted_jobs = merged[['ADADGUID', 'Province', 'To']].copy()\n",
    "\n",
    "# Compute adjusted values\n",
    "for col in cola:\n",
    "    rate_col = f'{col}_R'\n",
    "    prefix = col[:2]\n",
    "\n",
    "    if prefix in ['21', '22']:\n",
    "        source_col = '21'\n",
    "    elif prefix in ['31', '32', '33']:\n",
    "        source_col = '31'\n",
    "    else:\n",
    "        source_col = prefix\n",
    "\n",
    "    adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
    "\n",
    "adjusted_jobs['Sum'] = adjusted_jobs.drop(columns=['ADADGUID', 'Province', 'To']).sum(axis=1)\n",
    "\n",
    "adjusted_jobs = adjusted_jobs.fillna(0)\n",
    "\n",
    "adjusted_jobs['Province'] = adjusted_jobs['Province'].mask(\n",
    "    adjusted_jobs['Province'].isin([0, np.nan]),\n",
    "    adjusted_jobs['ADADGUID'].str[9:11].astype(int).map(province_code)\n",
    ")\n",
    "\n",
    "adjusted_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38222000-ec1c-4690-b257-684257b37c00",
   "metadata": {},
   "source": [
    "# STEP 10: Applying Export Weights to the Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b57b0f-8436-4df5-af3a-3f7ae6e02e8c",
   "metadata": {},
   "source": [
    "Export weights from Step 4 are applied to account for regional differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27a70d30-d89b-40bb-91ea-d09ea2766c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>naics</th>\n",
       "      <th>Province</th>\n",
       "      <th>ProvinceRate</th>\n",
       "      <th>111110_r</th>\n",
       "      <th>111120_r</th>\n",
       "      <th>111130_r</th>\n",
       "      <th>111140_r</th>\n",
       "      <th>111150_r</th>\n",
       "      <th>111160_r</th>\n",
       "      <th>111190_r</th>\n",
       "      <th>111211_r</th>\n",
       "      <th>...</th>\n",
       "      <th>337215_r</th>\n",
       "      <th>337910_r</th>\n",
       "      <th>337920_r</th>\n",
       "      <th>339110_r</th>\n",
       "      <th>339910_r</th>\n",
       "      <th>339920_r</th>\n",
       "      <th>339930_r</th>\n",
       "      <th>339940_r</th>\n",
       "      <th>339950_r</th>\n",
       "      <th>339990_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL_Rate</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.037429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845708</td>\n",
       "      <td>0.514049</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.459226</td>\n",
       "      <td>0.443710</td>\n",
       "      <td>0.531677</td>\n",
       "      <td>0.346251</td>\n",
       "      <td>0.701242</td>\n",
       "      <td>0.470009</td>\n",
       "      <td>0.469975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BC</td>\n",
       "      <td>BC_Rate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.243865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760972</td>\n",
       "      <td>0.186107</td>\n",
       "      <td>0.189876</td>\n",
       "      <td>0.538893</td>\n",
       "      <td>0.633485</td>\n",
       "      <td>0.409661</td>\n",
       "      <td>0.241962</td>\n",
       "      <td>0.726585</td>\n",
       "      <td>0.598870</td>\n",
       "      <td>0.349176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB</td>\n",
       "      <td>MB_Rate</td>\n",
       "      <td>0.064938</td>\n",
       "      <td>0.103250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032811</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851964</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.175574</td>\n",
       "      <td>0.450404</td>\n",
       "      <td>0.258747</td>\n",
       "      <td>0.457369</td>\n",
       "      <td>0.316760</td>\n",
       "      <td>0.809208</td>\n",
       "      <td>0.663664</td>\n",
       "      <td>0.574522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>NB_Rate</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.136710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853178</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.162405</td>\n",
       "      <td>0.741850</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.149737</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.804283</td>\n",
       "      <td>0.642297</td>\n",
       "      <td>0.498666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NL</td>\n",
       "      <td>NL_Rate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360563</td>\n",
       "      <td>0.231186</td>\n",
       "      <td>0.481951</td>\n",
       "      <td>0.337158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NS</td>\n",
       "      <td>NS_Rate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608397</td>\n",
       "      <td>0.634471</td>\n",
       "      <td>0.536874</td>\n",
       "      <td>0.372909</td>\n",
       "      <td>0.048109</td>\n",
       "      <td>0.667704</td>\n",
       "      <td>0.545332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NU</td>\n",
       "      <td>NU_Rate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752273</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.683868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NW</td>\n",
       "      <td>NWT_Rate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ON</td>\n",
       "      <td>ON_Rate</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>0.406677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033932</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.315716</td>\n",
       "      <td>0.206290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824980</td>\n",
       "      <td>0.728146</td>\n",
       "      <td>0.174355</td>\n",
       "      <td>0.526610</td>\n",
       "      <td>0.700647</td>\n",
       "      <td>0.417990</td>\n",
       "      <td>0.233975</td>\n",
       "      <td>0.731903</td>\n",
       "      <td>0.639883</td>\n",
       "      <td>0.608112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PE</td>\n",
       "      <td>PEI_Rate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.296708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.670449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QC</td>\n",
       "      <td>QC_Rate</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.194542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835069</td>\n",
       "      <td>0.757829</td>\n",
       "      <td>0.188675</td>\n",
       "      <td>0.643938</td>\n",
       "      <td>0.749195</td>\n",
       "      <td>0.484751</td>\n",
       "      <td>0.326389</td>\n",
       "      <td>0.498074</td>\n",
       "      <td>0.651382</td>\n",
       "      <td>0.516122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SK</td>\n",
       "      <td>SK_Rate</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.052447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.280165</td>\n",
       "      <td>0.725253</td>\n",
       "      <td>0.482840</td>\n",
       "      <td>0.384623</td>\n",
       "      <td>0.812800</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.508794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>YK</td>\n",
       "      <td>YK_Rate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752273</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.548929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.683868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "naics Province ProvinceRate  111110_r  111120_r  111130_r  111140_r  111150_r  \\\n",
       "0           AL      AL_Rate  0.024138  0.037429       0.0  0.035477  0.370000   \n",
       "1           BC      BC_Rate  0.000000  0.031443       0.0  0.031522  0.243865   \n",
       "2           MB      MB_Rate  0.064938  0.103250       0.0  0.032811  0.370000   \n",
       "3           NB      NB_Rate  0.620000  0.136710       0.0  0.405714  0.000000   \n",
       "4           NL      NL_Rate  0.000000  0.678462       0.0  0.000000  0.000000   \n",
       "5           NS      NS_Rate  0.000000  0.000000       0.0  0.405714  0.000000   \n",
       "6           NU      NU_Rate  0.000000  0.000000       0.0  0.000000  0.000000   \n",
       "7           NW     NWT_Rate  0.000000  0.000000       0.0  0.000000  0.000000   \n",
       "8           ON      ON_Rate  0.057076  0.406677       0.0  0.033932  0.074227   \n",
       "9           PE     PEI_Rate  0.000000  0.678462       0.0  0.000000  0.000000   \n",
       "10          QC      QC_Rate  0.016695  0.043700       0.0  0.042229  0.194542   \n",
       "11          SK      SK_Rate  0.000728  0.052447       0.0  0.042095  0.000000   \n",
       "12          YK      YK_Rate  0.000000  0.000000       0.0  0.000000  0.000000   \n",
       "\n",
       "naics  111160_r  111190_r  111211_r  ...  337215_r  337910_r  337920_r  \\\n",
       "0      0.000000  0.117974       0.0  ...  0.845708  0.514049  0.190000   \n",
       "1      0.000000  0.156439       0.0  ...  0.760972  0.186107  0.189876   \n",
       "2      0.000000  0.264963       0.0  ...  0.851964  0.790000  0.175574   \n",
       "3      0.000000  0.000000       0.0  ...  0.853178  0.790000  0.162405   \n",
       "4      0.000000  0.000000       0.0  ...  0.818052  0.000000  0.000000   \n",
       "5      0.000000  0.000000       0.0  ...  0.792772  0.000000  0.000000   \n",
       "6      0.000000  0.000000       0.0  ...  0.000000  0.000000  0.000000   \n",
       "7      0.000000  0.000000       0.0  ...  0.000000  0.000000  0.000000   \n",
       "8      0.315716  0.206290       0.0  ...  0.824980  0.728146  0.174355   \n",
       "9      0.000000  0.370000       0.0  ...  0.095587  0.000000  0.000000   \n",
       "10     0.000000  0.180804       0.0  ...  0.835069  0.757829  0.188675   \n",
       "11     0.000000  0.155096       0.0  ...  0.854575  0.000000  0.190000   \n",
       "12     0.000000  0.000000       0.0  ...  0.854615  0.000000  0.000000   \n",
       "\n",
       "naics  339110_r  339910_r  339920_r  339930_r  339940_r  339950_r  339990_r  \n",
       "0      0.459226  0.443710  0.531677  0.346251  0.701242  0.470009  0.469975  \n",
       "1      0.538893  0.633485  0.409661  0.241962  0.726585  0.598870  0.349176  \n",
       "2      0.450404  0.258747  0.457369  0.316760  0.809208  0.663664  0.574522  \n",
       "3      0.741850  0.767692  0.149737  0.394500  0.804283  0.642297  0.498666  \n",
       "4      0.360563  0.231186  0.481951  0.337158  0.000000  0.000000  0.106638  \n",
       "5      0.608397  0.634471  0.536874  0.372909  0.048109  0.667704  0.545332  \n",
       "6      0.752273  0.767692  0.000000  0.394500  0.000000  0.668000  0.683868  \n",
       "7      0.000000  0.767692  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8      0.526610  0.700647  0.417990  0.233975  0.731903  0.639883  0.608112  \n",
       "9      0.000000  0.767692  0.296708  0.000000  0.000000  0.668000  0.670449  \n",
       "10     0.643938  0.749195  0.484751  0.326389  0.498074  0.651382  0.516122  \n",
       "11     0.280165  0.725253  0.482840  0.384623  0.812800  0.668000  0.508794  \n",
       "12     0.752273  0.767692  0.548929  0.000000  0.000000  0.668000  0.683868  \n",
       "\n",
       "[13 rows x 312 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Melt to long format\n",
    "long_weight = weight_naics.melt(id_vars='naics', var_name='ProvinceRate', value_name='Rate')\n",
    "\n",
    "long_weight['naics'] = long_weight['naics'].astype(str) + '_r'\n",
    "\n",
    "long_weight['Province'] = long_weight['ProvinceRate'].str[:2]\n",
    "\n",
    "# Step 2: Pivot to wide format\n",
    "weight_naics_pivot = long_weight.pivot(index=['Province', 'ProvinceRate'], columns='naics', values='Rate').reset_index()\n",
    "\n",
    "weight_naics_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a289acfa-a7f2-4449-9621-078398572828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Census</th>\n",
       "      <th>Auto_C</th>\n",
       "      <th>Alum_C</th>\n",
       "      <th>Steel_C</th>\n",
       "      <th>Cop_C</th>\n",
       "      <th>Lum_C</th>\n",
       "      <th>Ene_C</th>\n",
       "      <th>CUSMA_C</th>\n",
       "      <th>Total_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>3715.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  Census  Auto_C  Alum_C  Steel_C  Cop_C  Lum_C  Ene_C  \\\n",
       "0     2021S051610010001  3715.0     0.0     1.0      1.0    0.0    5.0    0.0   \n",
       "1     2021S051610010002  2120.0     6.0     8.0      8.0    1.0    3.0   12.0   \n",
       "2     2021S051610010003  4530.0     0.0     1.0      2.0    0.0    8.0   36.0   \n",
       "3     2021S051610010004  5145.0     6.0     9.0      8.0    1.0    4.0   24.0   \n",
       "4     2021S051610010005  5190.0     6.0     9.0      8.0    1.0    4.0   29.0   \n",
       "...                 ...     ...     ...     ...      ...    ...    ...    ...   \n",
       "5428  2021S051662080004   510.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "5429  2021S051662080005   465.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "5430  2021S051662080006   280.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "5431  2021S051662080007     0.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "5432  2021S051662080008     0.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "\n",
       "      CUSMA_C  Total_C  \n",
       "0       579.0    579.0  \n",
       "1        86.0     86.0  \n",
       "2       258.0    258.0  \n",
       "3       107.0    107.0  \n",
       "4       122.0    122.0  \n",
       "...       ...      ...  \n",
       "5428      0.0      0.0  \n",
       "5429      0.0      0.0  \n",
       "5430      0.0      0.0  \n",
       "5431      0.0      0.0  \n",
       "5432      0.0      0.0  \n",
       "\n",
       "[5433 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Merge adjusted_jobs with weight_naics_pivot on Province\n",
    "census_byjobs = adjusted_jobs.merge(weight_naics_pivot, on='Province', how='left')\n",
    "\n",
    "# Step 2: Multiply each column by its corresponding rate\n",
    "for col in cola:\n",
    "    rate_col = f'{col}_r'\n",
    "    \n",
    "    census_byjobs[col] = np.ceil(census_byjobs[col] * census_byjobs[rate_col])\n",
    "\n",
    "# Step 3: Keep only ADADGUID and updated values\n",
    "census_byjobs = census_byjobs[['ADADGUID', 'To'] + cola]\n",
    "\n",
    "# Define output dictionary\n",
    "grouped_data = {\n",
    "    'ADADGUID': census_byjobs['ADADGUID'],  # retain ADA ID\n",
    "    'Census': census_byjobs['To'],\n",
    "    'Auto_C': census_byjobs[[col for col in cola if col in auto_naics]].sum(axis=1),\n",
    "    'Alum_C': census_byjobs[[col for col in cola if col in alum_naics]].sum(axis=1),\n",
    "    'Steel_C': census_byjobs[[col for col in cola if col in steel_naics]].sum(axis=1),\n",
    "    'Cop_C': census_byjobs[[col for col in cola if col in copper_naics]].sum(axis=1),\n",
    "    'Lum_C': census_byjobs[[col for col in cola if col in lum_naics]].sum(axis=1),\n",
    "    'Ene_C': census_byjobs[[col for col in cola if col in ene_naics]].sum(axis=1),\n",
    "    'CUSMA_C': census_byjobs[[col for col in cola if col in noncusma_naics]].sum(axis=1),\n",
    "    'Total_C': census_byjobs.iloc[:, 2:].sum(axis=1)\n",
    "}\n",
    "\n",
    "# Create final grouped DataFrame\n",
    "census_bytariffs = pd.DataFrame(grouped_data)\n",
    "census_bytariffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516dc4f-87db-4cb8-8265-db06293e4927",
   "metadata": {},
   "source": [
    "# STEP 11: Processing and adding the data to Choropleth and Centroid GDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831fcbc6-e7dd-40f2-9bdd-9667495d6510",
   "metadata": {},
   "source": [
    "Add the data on employees (by primary residence) to the GDFs produced in Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27c4f08f-d794-4c9b-a112-d8913ee4f767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Auto_B</th>\n",
       "      <th>Alum_B</th>\n",
       "      <th>Steel_B</th>\n",
       "      <th>Cop_B</th>\n",
       "      <th>Lum_B</th>\n",
       "      <th>Ene_B</th>\n",
       "      <th>CUSMA_B</th>\n",
       "      <th>Total_B</th>\n",
       "      <th>Auto_E</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_E</th>\n",
       "      <th>Auto_C</th>\n",
       "      <th>Alum_C</th>\n",
       "      <th>Steel_C</th>\n",
       "      <th>Cop_C</th>\n",
       "      <th>Lum_C</th>\n",
       "      <th>Ene_C</th>\n",
       "      <th>CUSMA_C</th>\n",
       "      <th>Total_C</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>POINT (-53.25419 47.86225)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>POINT (-52.76054 47.72309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>POINT (-53.26649 47.73593)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>POINT (-52.71312 47.62177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>POINT (-52.7703 47.64725)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-115.3713 67.80897)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-95.88322 68.64144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-89.80822 68.53258)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-107.82111 67.68532)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-108.11145 66.83118)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  Auto_B  Alum_B  Steel_B  Cop_B  Lum_B  Ene_B  \\\n",
       "0     2021S051610010001       0       1        1      0      2      0   \n",
       "1     2021S051610010002       0       0        0      0      0      0   \n",
       "2     2021S051610010003       0       1        1      0      4      0   \n",
       "3     2021S051610010004       0       1        1      1      0      2   \n",
       "4     2021S051610010005       2       1        1      0      0      0   \n",
       "...                 ...     ...     ...      ...    ...    ...    ...   \n",
       "5428  2021S051662080004       0       0        0      0      0      0   \n",
       "5429  2021S051662080005       0       0        0      0      0      0   \n",
       "5430  2021S051662080006       0       0        0      0      0      0   \n",
       "5431  2021S051662080007       0       0        0      0      0      0   \n",
       "5432  2021S051662080008       0       0        0      0      0      0   \n",
       "\n",
       "      CUSMA_B  Total_B  Auto_E  ...  Total_E  Auto_C  Alum_C  Steel_C  Cop_C  \\\n",
       "0          16       16       0  ...      791     0.0     1.0      1.0    0.0   \n",
       "1           2        2       0  ...       10     6.0     8.0      8.0    1.0   \n",
       "2           9        9       0  ...       49     0.0     1.0      2.0    0.0   \n",
       "3           7        7       0  ...       67     6.0     9.0      8.0    1.0   \n",
       "4           5        5       5  ...       29     6.0     9.0      8.0    1.0   \n",
       "...       ...      ...     ...  ...      ...     ...     ...      ...    ...   \n",
       "5428        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "5429        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "5430        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "5431        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "5432        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "\n",
       "      Lum_C  Ene_C  CUSMA_C  Total_C                     geometry  \n",
       "0       5.0    0.0    579.0    579.0   POINT (-53.25419 47.86225)  \n",
       "1       3.0   12.0     86.0     86.0   POINT (-52.76054 47.72309)  \n",
       "2       8.0   36.0    258.0    258.0   POINT (-53.26649 47.73593)  \n",
       "3       4.0   24.0    107.0    107.0   POINT (-52.71312 47.62177)  \n",
       "4       4.0   29.0    122.0    122.0    POINT (-52.7703 47.64725)  \n",
       "...     ...    ...      ...      ...                          ...  \n",
       "5428    0.0    0.0      0.0      0.0   POINT (-115.3713 67.80897)  \n",
       "5429    0.0    0.0      0.0      0.0   POINT (-95.88322 68.64144)  \n",
       "5430    0.0    0.0      0.0      0.0   POINT (-89.80822 68.53258)  \n",
       "5431    0.0    0.0      0.0      0.0  POINT (-107.82111 67.68532)  \n",
       "5432    0.0    0.0      0.0      0.0  POINT (-108.11145 66.83118)  \n",
       "\n",
       "[5433 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = cent_gdf.merge(census_bytariffs, on='ADADGUID', how='left')\n",
    "centroids = centroids[['ADADGUID'] + [f'{tar}_B' for tar in tars] + [f'{tar}_E' for tar in tars] + [f'{tar}_C' for tar in tars] + ['geometry']]\n",
    "centroids = centroids.to_crs('EPSG:4326')\n",
    "centroids.to_file('centroids.geojson', driver='GeoJSON')\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5c7033e-0368-42c2-ada7-f5cc5c978e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Census</th>\n",
       "      <th>Auto_3</th>\n",
       "      <th>Alum_3</th>\n",
       "      <th>Steel_3</th>\n",
       "      <th>Cop_3</th>\n",
       "      <th>Lum_3</th>\n",
       "      <th>Ene_3</th>\n",
       "      <th>CUSMA_3</th>\n",
       "      <th>Total_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>3715.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155855</td>\n",
       "      <td>0.155855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.040566</td>\n",
       "      <td>0.040566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.056954</td>\n",
       "      <td>0.056954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>0.020797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.023507</td>\n",
       "      <td>0.023507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  Census    Auto_3    Alum_3   Steel_3     Cop_3  \\\n",
       "0     2021S051610010001  3715.0  0.000000  0.000269  0.000269  0.000000   \n",
       "1     2021S051610010002  2120.0  0.002830  0.003774  0.003774  0.000472   \n",
       "2     2021S051610010003  4530.0  0.000000  0.000221  0.000442  0.000000   \n",
       "3     2021S051610010004  5145.0  0.001166  0.001749  0.001555  0.000194   \n",
       "4     2021S051610010005  5190.0  0.001156  0.001734  0.001541  0.000193   \n",
       "...                 ...     ...       ...       ...       ...       ...   \n",
       "5428  2021S051662080004   510.0  0.000000  0.000000  0.000000  0.000000   \n",
       "5429  2021S051662080005   465.0  0.000000  0.000000  0.000000  0.000000   \n",
       "5430  2021S051662080006   280.0  0.000000  0.000000  0.000000  0.000000   \n",
       "5431  2021S051662080007     0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "5432  2021S051662080008     0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         Lum_3     Ene_3   CUSMA_3   Total_3  \n",
       "0     0.001346  0.000000  0.155855  0.155855  \n",
       "1     0.001415  0.005660  0.040566  0.040566  \n",
       "2     0.001766  0.007947  0.056954  0.056954  \n",
       "3     0.000777  0.004665  0.020797  0.020797  \n",
       "4     0.000771  0.005588  0.023507  0.023507  \n",
       "...        ...       ...       ...       ...  \n",
       "5428  0.000000  0.000000  0.000000  0.000000  \n",
       "5429  0.000000  0.000000  0.000000  0.000000  \n",
       "5430  0.000000  0.000000  0.000000  0.000000  \n",
       "5431  0.000000  0.000000  0.000000  0.000000  \n",
       "5432  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5433 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_bytariffs = census_bytariffs.copy()\n",
    "\n",
    "for tar in tars:\n",
    "    tar_3 = f'{tar}_3'\n",
    "\n",
    "    perc_bytariffs[tar_3] = (\n",
    "        perc_bytariffs[f'{tar}_C']/perc_bytariffs['Census']\n",
    "    )\n",
    "\n",
    "perc_bytariffs = perc_bytariffs[['ADADGUID', 'Census'] + [f'{tar}_3' for tar in tars]]\n",
    "perc_bytariffs = perc_bytariffs.fillna(0)\n",
    "perc_bytariffs['CUSMA_3'] = perc_bytariffs['CUSMA_3'].clip(upper=1)\n",
    "perc_bytariffs['Total_3'] = perc_bytariffs['Total_3'].clip(upper=1)\n",
    "perc_bytariffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e1cc893-492b-4034-beb6-32880e6170a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>All_Businesses</th>\n",
       "      <th>All_Employees</th>\n",
       "      <th>Census</th>\n",
       "      <th>Auto_1</th>\n",
       "      <th>Alum_1</th>\n",
       "      <th>Steel_1</th>\n",
       "      <th>Cop_1</th>\n",
       "      <th>Lum_1</th>\n",
       "      <th>Ene_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_2</th>\n",
       "      <th>Auto_3</th>\n",
       "      <th>Alum_3</th>\n",
       "      <th>Steel_3</th>\n",
       "      <th>Cop_3</th>\n",
       "      <th>Lum_3</th>\n",
       "      <th>Ene_3</th>\n",
       "      <th>CUSMA_3</th>\n",
       "      <th>Total_3</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>219</td>\n",
       "      <td>2910</td>\n",
       "      <td>3715.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155855</td>\n",
       "      <td>0.155855</td>\n",
       "      <td>MULTIPOLYGON (((-53.51451 47.69912, -53.51464 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>66</td>\n",
       "      <td>394</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.040566</td>\n",
       "      <td>0.040566</td>\n",
       "      <td>POLYGON ((-52.78543 47.80961, -52.78542 47.809...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>288</td>\n",
       "      <td>4186</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.056954</td>\n",
       "      <td>0.056954</td>\n",
       "      <td>MULTIPOLYGON (((-53.12645 47.81702, -53.12663 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>438</td>\n",
       "      <td>9064</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>POLYGON ((-52.66902 47.66588, -52.66898 47.665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>203</td>\n",
       "      <td>1441</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.023507</td>\n",
       "      <td>0.023507</td>\n",
       "      <td>POLYGON ((-52.73992 47.69568, -52.74026 47.694...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>11</td>\n",
       "      <td>356</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((-115.34503 67.89695, -115.3453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>13</td>\n",
       "      <td>414</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((-95.82942 68.59941, -95.82932 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>8</td>\n",
       "      <td>295</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((-89.84909 68.53759, -89.84931 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((-107.9628 67.7012, -107.9628 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((-108.08644 66.85966, -108.0865...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  All_Businesses  All_Employees  Census    Auto_1  \\\n",
       "0     2021S051610010001             219           2910  3715.0  0.000000   \n",
       "1     2021S051610010002              66            394  2120.0  0.000000   \n",
       "2     2021S051610010003             288           4186  4530.0  0.000000   \n",
       "3     2021S051610010004             438           9064  5145.0  0.000000   \n",
       "4     2021S051610010005             203           1441  5190.0  0.009852   \n",
       "...                 ...             ...            ...     ...       ...   \n",
       "5428  2021S051662080004              11            356   510.0  0.000000   \n",
       "5429  2021S051662080005              13            414   465.0  0.000000   \n",
       "5430  2021S051662080006               8            295   280.0  0.000000   \n",
       "5431  2021S051662080007               0              0     0.0  0.000000   \n",
       "5432  2021S051662080008               0              0     0.0  0.000000   \n",
       "\n",
       "        Alum_1   Steel_1     Cop_1     Lum_1     Ene_1  ...   Total_2  \\\n",
       "0     0.004566  0.004566  0.000000  0.009132  0.000000  ...  0.271821   \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.025381   \n",
       "2     0.003472  0.003472  0.000000  0.013889  0.000000  ...  0.011706   \n",
       "3     0.002283  0.002283  0.002283  0.000000  0.004566  ...  0.007392   \n",
       "4     0.004926  0.004926  0.000000  0.000000  0.000000  ...  0.020125   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "5428  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "5429  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "5430  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "5431  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "5432  0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "\n",
       "        Auto_3    Alum_3   Steel_3     Cop_3     Lum_3     Ene_3   CUSMA_3  \\\n",
       "0     0.000000  0.000269  0.000269  0.000000  0.001346  0.000000  0.155855   \n",
       "1     0.002830  0.003774  0.003774  0.000472  0.001415  0.005660  0.040566   \n",
       "2     0.000000  0.000221  0.000442  0.000000  0.001766  0.007947  0.056954   \n",
       "3     0.001166  0.001749  0.001555  0.000194  0.000777  0.004665  0.020797   \n",
       "4     0.001156  0.001734  0.001541  0.000193  0.000771  0.005588  0.023507   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5428  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5429  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5430  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5431  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5432  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       Total_3                                           geometry  \n",
       "0     0.155855  MULTIPOLYGON (((-53.51451 47.69912, -53.51464 ...  \n",
       "1     0.040566  POLYGON ((-52.78543 47.80961, -52.78542 47.809...  \n",
       "2     0.056954  MULTIPOLYGON (((-53.12645 47.81702, -53.12663 ...  \n",
       "3     0.020797  POLYGON ((-52.66902 47.66588, -52.66898 47.665...  \n",
       "4     0.023507  POLYGON ((-52.73992 47.69568, -52.74026 47.694...  \n",
       "...        ...                                                ...  \n",
       "5428  0.000000  MULTIPOLYGON (((-115.34503 67.89695, -115.3453...  \n",
       "5429  0.000000  MULTIPOLYGON (((-95.82942 68.59941, -95.82932 ...  \n",
       "5430  0.000000  MULTIPOLYGON (((-89.84909 68.53759, -89.84931 ...  \n",
       "5431  0.000000  MULTIPOLYGON (((-107.9628 67.7012, -107.9628 6...  \n",
       "5432  0.000000  MULTIPOLYGON (((-108.08644 66.85966, -108.0865...  \n",
       "\n",
       "[5433 rows x 29 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choropleth = choro_gdf.merge(perc_bytariffs, on='ADADGUID', how='right')\n",
    "choropleth = choropleth[['ADADGUID', 'All_Businesses', 'All_Employees', 'Census'] + [f'{tar}_1' for tar in tars] + [f'{tar}_2' for tar in tars] + [f'{tar}_3' for tar in tars] + ['geometry']]\n",
    "choropleth = choropleth.to_crs('EPSG:4326')\n",
    "choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03e1ead8-0bf8-4feb-9c50-35df5f08b465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_12344\\4259686084.py:2: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  choropleth.to_file('choropleth.shp', driver='ESRI Shapefile')\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'All_Businesses' to 'All_Busine'\n",
      "  ogr_write(\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'All_Employees' to 'All_Employ'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "choropleth.to_file('choropleth.geojson', driver='GeoJSON')\n",
    "choropleth.to_file('choropleth.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377f1e6-da2d-4acb-b439-4cdec0139498",
   "metadata": {},
   "source": [
    "# CSV Trails\n",
    "\n",
    "for double-checking purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ac8c09d-1b88-4feb-9ce6-d5eed99efbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_grouped.drop(columns='geometry').to_csv('trail.csv', index=False)\n",
    "business_filter.drop(columns='geometry').to_csv('trail2.csv', index=False)\n",
    "business_census.to_csv('trail3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e0f5ad8-ad09-4703-bd87-470945cd7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "choro_cols.drop(columns='geometry').to_csv('trail4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "109a28ab-60ef-4f10-a7a5-a735ce372f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv('trail5.csv')\n",
    "jobs_rate.to_csv('trail6.csv')\n",
    "adjusted_jobs.to_csv('trail7.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
