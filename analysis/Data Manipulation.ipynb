{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b1c8a3-9dc5-4fa0-b61b-895477a018b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f41f1-68d6-44d1-b3dc-b9c8cd1f9056",
   "metadata": {},
   "source": [
    "# STEP 3: Connecting Tariffed HS Codes, NAICS Codes and respective CUSMA Non-Utilisation Rates via Concordance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa764029-c2f2-4aa6-a780-78fdc71307d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tariffed = pd.read_csv('tariff-hscodes.csv', encoding_errors='ignore', dtype={'HS Code': str})\n",
    "\n",
    "tariffed['HS_Code_6digit'] = (\n",
    "    tariffed['HS Code']\n",
    "    .str.replace('.', '', regex=False)\n",
    "    .str[:6]\n",
    ")\n",
    "\n",
    "tariffed = tariffed[['HS_Code_6digit', 'Category']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e34b98-821b-4c25-8f01-631b3f80349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = pd.read_csv('C616_HS8toNaics6_concord_202505.csv', dtype={'hts10': str})\n",
    "\n",
    "concordance['HS_Code_6digit'] = (\n",
    "    concordance['HS8 Code']\n",
    "    .astype(str)\n",
    "    .str.zfill(8)\n",
    "    .str[:6]\n",
    ")\n",
    "\n",
    "concordance['HS_Code_2digit'] = (\n",
    "    concordance['HS8 Code']\n",
    "    .astype(str)\n",
    "    .str.zfill(8)\n",
    "    .str[:2]\n",
    ")\n",
    "\n",
    "concordance['NAICS'] = concordance['NAICS 6 Code'].astype(str)\n",
    "\n",
    "concordance = concordance[['HS_Code_6digit', 'NAICS', 'HS_Code_2digit']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66352da6-6063-4f50-bea7-943a80938373",
   "metadata": {},
   "outputs": [],
   "source": [
    "util = pd.read_csv('USMCA Utilization Data.csv')\n",
    "\n",
    "util['HS_Code_2digit'] = (\n",
    "    util['HS Classification']\n",
    "    .astype(str)\n",
    "    .str[:2]\n",
    ")\n",
    "\n",
    "util['nonutil_rate'] = util['USMCA_Nonutilisation_May2025']\n",
    "\n",
    "util = util[['HS_Code_2digit', 'nonutil_rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b5582-14de-46e7-a267-3e63d87bf692",
   "metadata": {},
   "source": [
    "Setting the non-utilisation rate for those with sectoral tariffs at 1 reflects the fact that the 35% tariffs on non-CUSMA goods does not apply to the sectoral tariffs and that producers impacted by sectoral tariffs cannot use CUSMA to get their goods tariff-free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31aa998-e417-4eb6-9552-0c25e8ff265b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS_Code_6digit</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>HS_Code_2digit</th>\n",
       "      <th>Category</th>\n",
       "      <th>count</th>\n",
       "      <th>nonutil_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010110</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010121</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010129</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010130</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010190</td>\n",
       "      <td>112920</td>\n",
       "      <td>01</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>961620</td>\n",
       "      <td>314990</td>\n",
       "      <td>96</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6970</th>\n",
       "      <td>961700</td>\n",
       "      <td>332439</td>\n",
       "      <td>96</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6971</th>\n",
       "      <td>961800</td>\n",
       "      <td>339990</td>\n",
       "      <td>96</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6972</th>\n",
       "      <td>961900</td>\n",
       "      <td>322291</td>\n",
       "      <td>96</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>962000</td>\n",
       "      <td>322291</td>\n",
       "      <td>96</td>\n",
       "      <td>nonCUSMA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6974 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HS_Code_6digit   NAICS HS_Code_2digit  Category  count  nonutil_rate\n",
       "0            010110  112920             01  nonCUSMA      1          0.42\n",
       "1            010121  112920             01  nonCUSMA      1          0.42\n",
       "2            010129  112920             01  nonCUSMA      1          0.42\n",
       "3            010130  112920             01  nonCUSMA      1          0.42\n",
       "4            010190  112920             01  nonCUSMA      1          0.42\n",
       "...             ...     ...            ...       ...    ...           ...\n",
       "6969         961620  314990             96  nonCUSMA      1          0.84\n",
       "6970         961700  332439             96  nonCUSMA      1          0.84\n",
       "6971         961800  339990             96  nonCUSMA      1          0.84\n",
       "6972         961900  322291             96  nonCUSMA      1          0.84\n",
       "6973         962000  322291             96  nonCUSMA      1          0.84\n",
       "\n",
       "[6974 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naics_tar = concordance.merge(tariffed, on='HS_Code_6digit', how='left')\n",
    "\n",
    "counts = naics_tar['HS_Code_6digit'].value_counts().reset_index()\n",
    "naics_tarc = naics_tar.merge(counts, on='HS_Code_6digit', how='left')\n",
    "\n",
    "naics_imp = naics_tarc.merge(util, on='HS_Code_2digit', how='left')\n",
    "\n",
    "# Making the codes with a sectoral tariff category assigned to have a non-util rate value of 1\n",
    "# This ensures that when multiplied later, sectoral tariffs do not affect the CUSMA non-utilisation rates to compute the impact of nonCUSMA 35% tariffs\n",
    "naics_imp.loc[naics_imp['Category'].notna(), 'nonutil_rate'] = 1\n",
    "naics_imp['Category'] = naics_imp['Category'].fillna('nonCUSMA')\n",
    "naics_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe76b5c-45df-4f0a-9bdb-f4a64be60a5c",
   "metadata": {},
   "source": [
    "# STEP 4: Getting Weights by Province/Territory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a5831-a579-4abf-8500-04124e5d4c93",
   "metadata": {},
   "source": [
    "Since multiple NAICS codes may contribute to the production of one HS code product, and we do not how much of a part does each NAICS contribute to the whole HS code good production, **thus an assumption is made to divide them equally**. Hence, when each export value is added, it is divided them by the count (how many times does that HS Code get repeated).  \n",
    "\n",
    "Meanwhile, the non-utilisation rate of CUSMA exemption by each HS Code is first multiplied to the total value of each HS Code export to the US, before divided by the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f7ef2c-1f20-4934-bdf9-19de81ca172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS_Code_6digit</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NL_Global</th>\n",
       "      <th>NL_US</th>\n",
       "      <th>PEI_Global</th>\n",
       "      <th>PEI_US</th>\n",
       "      <th>NS_Global</th>\n",
       "      <th>NS_US</th>\n",
       "      <th>NB_Global</th>\n",
       "      <th>NB_US</th>\n",
       "      <th>...</th>\n",
       "      <th>AL_Global</th>\n",
       "      <th>AL_US</th>\n",
       "      <th>BC_Global</th>\n",
       "      <th>BC_US</th>\n",
       "      <th>YK_Global</th>\n",
       "      <th>YK_US</th>\n",
       "      <th>NWT_Global</th>\n",
       "      <th>NWT_US</th>\n",
       "      <th>NU_Global</th>\n",
       "      <th>NU_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010110</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010121</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>102006.0</td>\n",
       "      <td>42842.52</td>\n",
       "      <td>43608.0</td>\n",
       "      <td>18315.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010129</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103341.0</td>\n",
       "      <td>43403.22</td>\n",
       "      <td>767570.0</td>\n",
       "      <td>322379.40</td>\n",
       "      <td>245243.0</td>\n",
       "      <td>103002.06</td>\n",
       "      <td>...</td>\n",
       "      <td>38107217.0</td>\n",
       "      <td>6846298.20</td>\n",
       "      <td>8940055.0</td>\n",
       "      <td>3722693.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010130</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5591.0</td>\n",
       "      <td>2348.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16453.0</td>\n",
       "      <td>6910.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010190</td>\n",
       "      <td>112920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>961620</td>\n",
       "      <td>314990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26374.0</td>\n",
       "      <td>19699.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6970</th>\n",
       "      <td>961700</td>\n",
       "      <td>332439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>3741.36</td>\n",
       "      <td>191510.0</td>\n",
       "      <td>58298.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6971</th>\n",
       "      <td>961800</td>\n",
       "      <td>339990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57388.0</td>\n",
       "      <td>30522.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6972</th>\n",
       "      <td>961900</td>\n",
       "      <td>322291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>113029441.0</td>\n",
       "      <td>94496776.08</td>\n",
       "      <td>...</td>\n",
       "      <td>10736.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>408726.0</td>\n",
       "      <td>4863.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>962000</td>\n",
       "      <td>322291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20243.0</td>\n",
       "      <td>17004.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>169613.0</td>\n",
       "      <td>82445.16</td>\n",
       "      <td>6675.0</td>\n",
       "      <td>3125.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6974 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HS_Code_6digit   NAICS  NL_Global  NL_US  PEI_Global    PEI_US  \\\n",
       "0            010110  112920        0.0    0.0         0.0      0.00   \n",
       "1            010121  112920        0.0    0.0         0.0      0.00   \n",
       "2            010129  112920        0.0    0.0    103341.0  43403.22   \n",
       "3            010130  112920        0.0    0.0         0.0      0.00   \n",
       "4            010190  112920        0.0    0.0         0.0      0.00   \n",
       "...             ...     ...        ...    ...         ...       ...   \n",
       "6969         961620  314990        0.0    0.0         0.0      0.00   \n",
       "6970         961700  332439        0.0    0.0         0.0      0.00   \n",
       "6971         961800  339990        0.0    0.0         0.0      0.00   \n",
       "6972         961900  322291        0.0    0.0         0.0      0.00   \n",
       "6973         962000  322291        0.0    0.0         0.0      0.00   \n",
       "\n",
       "      NS_Global      NS_US    NB_Global        NB_US  ...   AL_Global  \\\n",
       "0           0.0       0.00          0.0         0.00  ...         0.0   \n",
       "1           0.0       0.00          0.0         0.00  ...    102006.0   \n",
       "2      767570.0  322379.40     245243.0    103002.06  ...  38107217.0   \n",
       "3           0.0       0.00       5591.0      2348.22  ...         0.0   \n",
       "4           0.0       0.00          0.0         0.00  ...         0.0   \n",
       "...         ...        ...          ...          ...  ...         ...   \n",
       "6969        0.0       0.00          0.0         0.00  ...         0.0   \n",
       "6970        9.0       0.00          0.0         0.00  ...      4454.0   \n",
       "6971        0.0       0.00          0.0         0.00  ...         0.0   \n",
       "6972        0.0       0.00  113029441.0  94496776.08  ...     10736.0   \n",
       "6973    20243.0   17004.12          0.0         0.00  ...    169613.0   \n",
       "\n",
       "           AL_US  BC_Global       BC_US  YK_Global  YK_US  NWT_Global  NWT_US  \\\n",
       "0           0.00        0.0        0.00        0.0    0.0         0.0     0.0   \n",
       "1       42842.52    43608.0    18315.36        0.0    0.0         0.0     0.0   \n",
       "2     6846298.20  8940055.0  3722693.10        0.0    0.0         0.0     0.0   \n",
       "3           0.00    16453.0     6910.26        0.0    0.0         0.0     0.0   \n",
       "4           0.00        0.0        0.00        0.0    0.0         0.0     0.0   \n",
       "...          ...        ...         ...        ...    ...         ...     ...   \n",
       "6969        0.00    26374.0    19699.68        0.0    0.0         0.0     0.0   \n",
       "6970     3741.36   191510.0    58298.52        0.0    0.0         0.0     0.0   \n",
       "6971        0.00    57388.0    30522.24        0.0    0.0         0.0     0.0   \n",
       "6972        0.00   408726.0     4863.60        0.0    0.0         0.0     0.0   \n",
       "6973    82445.16     6675.0     3125.64        0.0    0.0         0.0     0.0   \n",
       "\n",
       "      NU_Global  NU_US  \n",
       "0           0.0    0.0  \n",
       "1           0.0    0.0  \n",
       "2           0.0    0.0  \n",
       "3           0.0    0.0  \n",
       "4           0.0    0.0  \n",
       "...         ...    ...  \n",
       "6969        0.0    0.0  \n",
       "6970        0.0    0.0  \n",
       "6971        0.0    0.0  \n",
       "6972        0.0    0.0  \n",
       "6973        0.0    0.0  \n",
       "\n",
       "[6974 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the DataFrame with NAICS data\n",
    "tariff_exp_val = naics_imp.copy()\n",
    "\n",
    "# Define all regions to process\n",
    "provinces = ['NL', 'PEI', 'NS', 'NB', 'QC', 'ON', 'MB', 'SK', 'AL', 'BC', 'YK', 'NWT', 'NU']\n",
    "cols = ['Commodity', 'Value ($)']\n",
    "\n",
    "for province in provinces:\n",
    "    # Process Global data\n",
    "    global_df = pd.read_csv(f'{province}-Global.csv', usecols=cols)\n",
    "    global_df['HS_Code_6digit'] = global_df['Commodity'].str.replace('.', '', regex=False).str[:6]\n",
    "    global_df[f'{province}_Global'] = global_df['Value ($)']\n",
    "    global_df = global_df[['HS_Code_6digit', f'{province}_Global']]\n",
    "    \n",
    "    tariff_exp_val = tariff_exp_val.merge(global_df, on='HS_Code_6digit', how='left')\n",
    "    tariff_exp_val[f'{province}_Global'] = tariff_exp_val[f'{province}_Global'] / tariff_exp_val['count']\n",
    "    \n",
    "    # Process US data\n",
    "    us_df = pd.read_csv(f'{province}-US.csv', usecols=cols)\n",
    "    us_df['HS_Code_6digit'] = us_df['Commodity'].str.replace('.', '', regex=False).str[:6]\n",
    "    us_df[f'{province}_US'] = us_df['Value ($)']\n",
    "    us_df = us_df[['HS_Code_6digit', f'{province}_US']]\n",
    "    \n",
    "    tariff_exp_val = tariff_exp_val.merge(us_df, on='HS_Code_6digit', how='left')\n",
    "    tariff_exp_val[f'{province}_US'] = (tariff_exp_val[f'{province}_US'] * tariff_exp_val['nonutil_rate']) / tariff_exp_val['count']\n",
    "\n",
    "# Drop the non-relevant columns\n",
    "tariff_exp_val = tariff_exp_val.drop(columns=['HS_Code_2digit', 'Category', 'count', 'nonutil_rate'])\n",
    "\n",
    "tariff_exp_val = tariff_exp_val.fillna(0)\n",
    "\n",
    "tariff_exp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6afb068-7004-48f2-bdd8-d36f5556b5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NL</th>\n",
       "      <th>PEI</th>\n",
       "      <th>NS</th>\n",
       "      <th>NB</th>\n",
       "      <th>QC</th>\n",
       "      <th>ON</th>\n",
       "      <th>MB</th>\n",
       "      <th>SK</th>\n",
       "      <th>AL</th>\n",
       "      <th>BC</th>\n",
       "      <th>YK</th>\n",
       "      <th>NWT</th>\n",
       "      <th>NU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>0.064938</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111120</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124930</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>0.371635</td>\n",
       "      <td>0.094353</td>\n",
       "      <td>0.047928</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.028733</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.045639</td>\n",
       "      <td>0.032567</td>\n",
       "      <td>0.030494</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.032376</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194542</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.243865</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>339920</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>0.227019</td>\n",
       "      <td>0.706480</td>\n",
       "      <td>0.243381</td>\n",
       "      <td>0.808154</td>\n",
       "      <td>0.653166</td>\n",
       "      <td>0.582863</td>\n",
       "      <td>0.866177</td>\n",
       "      <td>0.663320</td>\n",
       "      <td>0.587708</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>339930</td>\n",
       "      <td>0.358952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397013</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.347140</td>\n",
       "      <td>0.248730</td>\n",
       "      <td>0.337235</td>\n",
       "      <td>0.409485</td>\n",
       "      <td>0.368632</td>\n",
       "      <td>0.255254</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>339940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049719</td>\n",
       "      <td>0.831198</td>\n",
       "      <td>0.467514</td>\n",
       "      <td>0.732703</td>\n",
       "      <td>0.859608</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.720095</td>\n",
       "      <td>0.691042</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>339950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.149934</td>\n",
       "      <td>0.699527</td>\n",
       "      <td>0.748507</td>\n",
       "      <td>0.562703</td>\n",
       "      <td>0.151730</td>\n",
       "      <td>0.604759</td>\n",
       "      <td>0.206830</td>\n",
       "      <td>0.265313</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>339990</td>\n",
       "      <td>0.132630</td>\n",
       "      <td>0.485059</td>\n",
       "      <td>0.471560</td>\n",
       "      <td>0.330572</td>\n",
       "      <td>0.464566</td>\n",
       "      <td>0.597974</td>\n",
       "      <td>0.573977</td>\n",
       "      <td>0.349298</td>\n",
       "      <td>0.425631</td>\n",
       "      <td>0.269257</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NAICS        NL       PEI        NS        NB        QC        ON  \\\n",
       "0    111110  0.000000  0.000000  0.000000  0.620000  0.016695  0.057076   \n",
       "1    111120  0.620000  0.620000  0.000000  0.124930  0.039934  0.371635   \n",
       "2    111130  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3    111140  0.000000  0.000000  0.620000  0.620000  0.045639  0.032567   \n",
       "4    111150  0.000000  0.000000  0.000000  0.000000  0.194542  0.074227   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "305  339920  0.079019  0.227019  0.706480  0.243381  0.808154  0.653166   \n",
       "306  339930  0.358952  0.000000  0.397013  0.420000  0.347140  0.248730   \n",
       "307  339940  0.000000  0.000000  0.049719  0.831198  0.467514  0.732703   \n",
       "308  339950  0.000000  0.150000  0.149934  0.699527  0.748507  0.562703   \n",
       "309  339990  0.132630  0.485059  0.471560  0.330572  0.464566  0.597974   \n",
       "\n",
       "           MB        SK        AL        BC    YK  NWT    NU  \n",
       "0    0.064938  0.000728  0.024138  0.000000  0.00  0.0  0.00  \n",
       "1    0.094353  0.047928  0.034204  0.028733  0.00  0.0  0.00  \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.00  0.0  0.00  \n",
       "3    0.030494  0.038389  0.032376  0.028748  0.00  0.0  0.00  \n",
       "4    0.370000  0.000000  0.370000  0.243865  0.00  0.0  0.00  \n",
       "..        ...       ...       ...       ...   ...  ...   ...  \n",
       "305  0.582863  0.866177  0.663320  0.587708  1.00  0.0  0.00  \n",
       "306  0.337235  0.409485  0.368632  0.255254  0.00  0.0  0.42  \n",
       "307  0.859608  0.150000  0.720095  0.691042  0.00  0.0  0.00  \n",
       "308  0.151730  0.604759  0.206830  0.265313  0.15  0.0  0.15  \n",
       "309  0.573977  0.349298  0.425631  0.269257  0.87  0.0  0.24  \n",
       "\n",
       "[310 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Aggregate ONLY the necessary sums (Global/US columns)\n",
    "aggregates = {\n",
    "    **{f'{province}_Global': (f'{province}_Global', 'sum') for province in provinces},\n",
    "    **{f'{province}_US': (f'{province}_US', 'sum') for province in provinces},\n",
    "}\n",
    "\n",
    "weight_naics = tariff_exp_val.groupby('NAICS', as_index=False).agg(**aggregates)\n",
    "\n",
    "# Step 2: Compute rates and keep ONLY those columns\n",
    "for province in provinces:\n",
    "    global_col = f'{province}_Global'\n",
    "    us_col = f'{province}_US'\n",
    "    rate_col = f'{province}'\n",
    "    \n",
    "    weight_naics[rate_col] = (\n",
    "        weight_naics[us_col] / weight_naics[global_col]\n",
    "    )\n",
    "\n",
    "# Step 3: Select only naics, naics_2digit, and rate columns\n",
    "final_columns = ['NAICS'] + [f'{province}' for province in provinces]\n",
    "weight_naics = weight_naics[final_columns]\n",
    "weight_naics = weight_naics.fillna(0)\n",
    "\n",
    "# Result\n",
    "weight_naics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5357b847-43c8-4210-ad77-ce15d87fbd1a",
   "metadata": {},
   "source": [
    "# STEP 5: Using filtered NAICS Codes to filter directly-impacted businesses and estimate directly-impacted employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542741f5-cdbb-4940-8eef-4fa2678f2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_naics = set(naics_imp[naics_imp['Category'] == 'Auto']['NAICS'].unique())\n",
    "alum_naics = set(naics_imp[naics_imp['Category'] == 'Aluminum']['NAICS'].unique())\n",
    "steel_naics = set(naics_imp[naics_imp['Category'] == 'Steel']['NAICS'].unique())\n",
    "copper_naics = set(naics_imp[naics_imp['Category'] == 'Copper']['NAICS'].unique())\n",
    "lum_naics = set(naics_imp[naics_imp['Category'] == 'Lumber']['NAICS'].unique())\n",
    "ene_naics = set(naics_imp[naics_imp['Category'] == 'Energy Mineral']['NAICS'].unique())\n",
    "noncusma_naics = set(naics_imp[naics_imp['Category'] == 'nonCUSMA']['NAICS'].unique())\n",
    "total_naics = set(naics_imp['NAICS'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08840c94-33b1-4944-94c8-09a34ca11fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_i = ['DA',\n",
    "        'All_Businesses', 'All_Employees',\n",
    "        'Auto_B', 'Auto_E',\n",
    "        'Alum_B', 'Alum_E',\n",
    "        'Steel_B', 'Steel_E',\n",
    "        'Cop_B', 'Cop_E',\n",
    "        'Lum_B', 'Lum_E',\n",
    "        'Ene_B', 'Ene_E',\n",
    "        'CUSMA_B', 'CUSMA_E',\n",
    "        'Total_B', 'Total_E',\n",
    "        #add columns here, column titles are every value of total_naics\n",
    "       ]\n",
    "\n",
    "# Add individual NAICS codes as column headers for Est_Employees by NAICS\n",
    "col_i.extend(sorted(total_naics))\n",
    "\n",
    "business = pd.DataFrame(columns = col_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d841b517-4cac-48e1-a727-fbc8938ece72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 processed in 1.89 sec\n",
      "Chunk 2 processed in 1.62 sec\n",
      "Chunk 3 processed in 1.72 sec\n",
      "Chunk 4 processed in 1.57 sec\n",
      "Chunk 5 processed in 1.58 sec\n",
      "Chunk 6 processed in 1.55 sec\n",
      "Chunk 7 processed in 1.52 sec\n",
      "Chunk 8 processed in 1.66 sec\n",
      "Chunk 9 processed in 1.62 sec\n",
      "Chunk 10 processed in 1.54 sec\n",
      "Chunk 11 processed in 1.60 sec\n",
      "Chunk 12 processed in 1.63 sec\n",
      "Chunk 13 processed in 1.56 sec\n",
      "Chunk 14 processed in 1.55 sec\n",
      "Chunk 15 processed in 1.56 sec\n",
      "Chunk 16 processed in 1.57 sec\n",
      "Chunk 17 processed in 1.65 sec\n",
      "Chunk 18 processed in 1.60 sec\n",
      "Chunk 19 processed in 1.56 sec\n",
      "Chunk 20 processed in 1.32 sec\n",
      "Chunk 21 processed in 1.50 sec\n",
      "Chunk 22 processed in 1.51 sec\n",
      "Chunk 23 processed in 1.66 sec\n",
      "Chunk 24 processed in 1.45 sec\n",
      "Chunk 25 processed in 1.61 sec\n",
      "Chunk 26 processed in 1.29 sec\n",
      "Chunk 27 processed in 1.49 sec\n",
      "Chunk 28 processed in 1.46 sec\n",
      "Chunk 29 processed in 1.46 sec\n",
      "Chunk 30 processed in 1.48 sec\n",
      "Chunk 31 processed in 1.53 sec\n",
      "Chunk 32 processed in 1.52 sec\n",
      "Chunk 33 processed in 1.51 sec\n",
      "Chunk 34 processed in 1.52 sec\n",
      "Chunk 35 processed in 1.46 sec\n",
      "Chunk 36 processed in 1.49 sec\n",
      "Chunk 37 processed in 1.49 sec\n",
      "Chunk 38 processed in 1.47 sec\n",
      "Chunk 39 processed in 1.48 sec\n",
      "Chunk 40 processed in 1.46 sec\n",
      "Chunk 41 processed in 1.61 sec\n",
      "Chunk 42 processed in 1.54 sec\n",
      "Chunk 43 processed in 1.36 sec\n",
      "Chunk 44 processed in 1.62 sec\n",
      "Chunk 45 processed in 1.50 sec\n",
      "Chunk 46 processed in 1.50 sec\n",
      "Chunk 47 processed in 1.53 sec\n",
      "Chunk 48 processed in 1.49 sec\n",
      "Chunk 49 processed in 1.50 sec\n",
      "Chunk 50 processed in 1.47 sec\n",
      "Chunk 51 processed in 1.50 sec\n",
      "Chunk 52 processed in 0.30 sec\n",
      "\n",
      "✅ All chunks processed in 260.58 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>All_Businesses</th>\n",
       "      <th>All_Employees</th>\n",
       "      <th>Auto_B</th>\n",
       "      <th>Auto_E</th>\n",
       "      <th>Alum_B</th>\n",
       "      <th>Alum_E</th>\n",
       "      <th>Steel_B</th>\n",
       "      <th>Steel_E</th>\n",
       "      <th>Cop_B</th>\n",
       "      <th>...</th>\n",
       "      <th>337215</th>\n",
       "      <th>337910</th>\n",
       "      <th>337920</th>\n",
       "      <th>339110</th>\n",
       "      <th>339910</th>\n",
       "      <th>339920</th>\n",
       "      <th>339930</th>\n",
       "      <th>339940</th>\n",
       "      <th>339950</th>\n",
       "      <th>339990</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>170</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10010165</td>\n",
       "      <td>22</td>\n",
       "      <td>266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010166</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10010167</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10010168</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55246</th>\n",
       "      <td>62080023</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55247</th>\n",
       "      <td>62080024</td>\n",
       "      <td>11</td>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55248</th>\n",
       "      <td>62080025</td>\n",
       "      <td>11</td>\n",
       "      <td>356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55249</th>\n",
       "      <td>62080026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55250</th>\n",
       "      <td>62080027</td>\n",
       "      <td>13</td>\n",
       "      <td>414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55251 rows × 329 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DA  All_Businesses  All_Employees  Auto_B  Auto_E  Alum_B  \\\n",
       "0      10000000             170           1006     0.0     0.0     0.0   \n",
       "1      10010165              22            266     0.0     0.0     0.0   \n",
       "2      10010166               2              6     0.0     0.0     0.0   \n",
       "3      10010167               6             22     0.0     0.0     0.0   \n",
       "4      10010168               5             19     0.0     0.0     0.0   \n",
       "...         ...             ...            ...     ...     ...     ...   \n",
       "55246  62080023               2             10     0.0     0.0     0.0   \n",
       "55247  62080024              11            113     0.0     0.0     0.0   \n",
       "55248  62080025              11            356     0.0     0.0     0.0   \n",
       "55249  62080026               0              0     0.0     0.0     0.0   \n",
       "55250  62080027              13            414     0.0     0.0     0.0   \n",
       "\n",
       "       Alum_E  Steel_B  Steel_E  Cop_B  ...  337215  337910  337920  339110  \\\n",
       "0         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "1         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "2         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "3         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "4         0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "...       ...      ...      ...    ...  ...     ...     ...     ...     ...   \n",
       "55246     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "55247     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "55248     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "55249     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "55250     0.0      0.0      0.0    0.0  ...       0       0       0       0   \n",
       "\n",
       "       339910  339920  339930  339940  339950  339990  \n",
       "0           0       0       0       0       0       0  \n",
       "1           0       0       0       0       0       0  \n",
       "2           0       0       0       0       0       0  \n",
       "3           0       0       0       0       0       0  \n",
       "4           0       0       0       0       0       0  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "55246       0       0       0       0       0       0  \n",
       "55247       0       0       0       0       0       0  \n",
       "55248       0       0       0       0       0       0  \n",
       "55249       0       0       0       0       0       0  \n",
       "55250       0       0       0       0       0       0  \n",
       "\n",
       "[55251 rows x 329 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 1_000_000\n",
    "province_code = {10:'NL',11:'PEI',12:'NS',13:'NB',24:'QC',35:'ON',46:'MB',47:'SK',48:'AL',59:'BC',60:'YK',61:'NWT',62:'NU'}\n",
    "\n",
    "# melting weights in long form to prepare for a vectorized merge\n",
    "wlong = (\n",
    "    weight_naics\n",
    "    .melt(id_vars='NAICS', var_name='Province', value_name='Rate')\n",
    ")\n",
    "\n",
    "# making a category boolean mask to prepare to include which NAICS business/employee value under which tariff category\n",
    "def isin_mask(s, codes_set):\n",
    "    # s is NAICS series\n",
    "    return s.isin(codes_set) if len(codes_set) else pd.Series(False, index=s.index)\n",
    "\n",
    "# loading necessary data\n",
    "all_cols = pd.read_csv('Dec2022_Estabcounts_byDA.csv', encoding='ISO-8859-1', nrows=1).columns\n",
    "cols_to_keep = [c for c in all_cols if c != 'Without employees']\n",
    "\n",
    "# suggesting dtypes for performance purposes\n",
    "dtype_hint = {\n",
    "    '1-4':'Int64','5-9':'Int64','10-19':'Int64','20-49':'Int64',\n",
    "    '50-99':'Int64','100-199':'Int64','200-499':'Int64','500 +':'Int64',\n",
    "    'Total, with employees':'Int64',\n",
    "}\n",
    "\n",
    "total_start = time.time()\n",
    "chunk_num = 0\n",
    "\n",
    "# Preparing two empty lists\n",
    "agg_frames = []       # List for weighted amount of businesses and est employees for each tariff\n",
    "per_naics_frames = [] # List for total amount of employees for each NAICS code in each ADA --> needed for Step 8 later\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "        'Dec2022_Estabcounts_byDA.csv',\n",
    "        encoding='ISO-8859-1',\n",
    "        chunksize=chunk_size,\n",
    "        usecols=cols_to_keep,\n",
    "        dtype=dtype_hint,\n",
    "    ):\n",
    "    t0 = time.time()\n",
    "    chunk_num += 1\n",
    "\n",
    "    # 1) Filter non-relevant rows\n",
    "    chunk = chunk[~chunk['NAICS'].isin(['Sub-total, classified', 'Unclassified', 'Total'])].copy()\n",
    "\n",
    "    # 2) Basic transforms (vectorized)\n",
    "    # keep NAICS 6-digit as string\n",
    "    chunk['NAICS'] = chunk['NAICS'].astype(str).str[:6]\n",
    "    chunk['Business_per_NAICS'] = chunk['Total, with employees'].fillna(0)\n",
    "\n",
    "    # estimate employees (vectorized)\n",
    "    cols = ['1-4','5-9','10-19','20-49','50-99','100-199','200-499','500 +']\n",
    "    for c in cols:\n",
    "        chunk['Est_Employees'] = (\n",
    "            chunk['1-4'].fillna(0) * 3  +\n",
    "            chunk['5-9'].fillna(0) * 7  +\n",
    "            chunk['10-19'].fillna(0) * 15 +\n",
    "            chunk['20-49'].fillna(0) * 35 +\n",
    "            chunk['50-99'].fillna(0) * 75 +\n",
    "            chunk['100-199'].fillna(0) * 150 +\n",
    "            chunk['200-499'].fillna(0) * 350 +\n",
    "            chunk['500 +'].fillna(0) * 550\n",
    "        )\n",
    "\n",
    "    # Province lookup\n",
    "    # if 'DisseminationAre' isn’t numeric, ensure this still works (it uses first two chars)\n",
    "    chunk['ProvinceCode'] = chunk['DisseminationAre'].astype(str).str[:2].astype(int, errors='ignore')\n",
    "    chunk['Province'] = pd.Series(chunk['ProvinceCode']).map(province_code)\n",
    "\n",
    "    # 3) Merge the per-(NAICS, Province) Rate (vectorized, no apply)\n",
    "    merged = chunk.merge(wlong, how='left', on=['NAICS','Province'])\n",
    "\n",
    "    # 4) Weighted columns (vectorized)\n",
    "    merged['Weighted_Business']  = np.ceil(merged['Business_per_NAICS'] * merged['Rate'])\n",
    "    merged['Weighted_Employees'] = np.ceil(merged['Est_Employees'] * merged['Rate'])\n",
    "\n",
    "    # 5) Apply category masks to each of the tariff category to find the list of NAICS for each tariff type\n",
    "    s = merged['NAICS']\n",
    "    is_auto   = s.isin(auto_naics)\n",
    "    is_alum   = s.isin(alum_naics)\n",
    "    is_steel  = s.isin(steel_naics)\n",
    "    is_copper = s.isin(copper_naics)\n",
    "    is_lum    = s.isin(lum_naics)\n",
    "    is_ene    = s.isin(ene_naics)\n",
    "    is_cusma  = s.isin(noncusma_naics)\n",
    "    is_total  = s.isin(total_naics)\n",
    "\n",
    "    # 6) Build per-row contributions by multiplying masks (0/1) — vectorized\n",
    "    wb = merged['Weighted_Business']\n",
    "    we = merged['Weighted_Employees']\n",
    "\n",
    "    merged['Auto_B']  = np.where(is_auto,   wb, 0)\n",
    "    merged['Auto_E']  = np.where(is_auto,   we, 0)\n",
    "    merged['Alum_B']  = np.where(is_alum,   wb, 0)\n",
    "    merged['Alum_E']  = np.where(is_alum,   we, 0)\n",
    "    merged['Steel_B'] = np.where(is_steel,  wb, 0)\n",
    "    merged['Steel_E'] = np.where(is_steel,  we, 0)\n",
    "    merged['Cop_B']   = np.where(is_copper, wb, 0)\n",
    "    merged['Cop_E']   = np.where(is_copper, we, 0)\n",
    "    merged['Lum_B']   = np.where(is_lum,    wb, 0)\n",
    "    merged['Lum_E']   = np.where(is_lum,    we, 0)\n",
    "    merged['Ene_B']   = np.where(is_ene,    wb, 0)\n",
    "    merged['Ene_E']   = np.where(is_ene,    we, 0)\n",
    "    merged['CUSMA_B'] = np.where(is_cusma,  wb, 0)\n",
    "    merged['CUSMA_E'] = np.where(is_cusma,  we, 0)\n",
    "    merged['Total_B'] = np.where(is_total,  wb, 0)\n",
    "    merged['Total_E'] = np.where(is_total,  we, 0)\n",
    "\n",
    "    # Always aggregate the unweighted totals too\n",
    "    merged['All_Businesses'] = merged['Business_per_NAICS']\n",
    "    merged['All_Employees']  = merged['Est_Employees']\n",
    "\n",
    "    # 7) Chunk-level aggregation in ONE groupby\n",
    "    agg_cols = [\n",
    "        'All_Businesses','All_Employees',\n",
    "        'Auto_B','Auto_E','Alum_B','Alum_E','Steel_B','Steel_E',\n",
    "        'Cop_B','Cop_E','Lum_B','Lum_E','Ene_B','Ene_E',\n",
    "        'CUSMA_B','CUSMA_E','Total_B','Total_E'\n",
    "    ]\n",
    "    by_da = merged.groupby('DisseminationAre', as_index=False)[agg_cols].sum()\n",
    "\n",
    "    # 8) Generating the data for second list --> number of jobs per NAICS in each DA\n",
    "    per_naics = (\n",
    "        merged.loc[is_total, ['DisseminationAre','NAICS','Est_Employees']]\n",
    "        .pivot_table(index='DisseminationAre', columns='NAICS', values='Est_Employees',\n",
    "                     aggfunc='sum', fill_value=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Saving the data into the two different lists in each chunk\n",
    "    agg_frames.append(by_da)\n",
    "    per_naics_frames.append(per_naics)\n",
    "\n",
    "    print(f\"Chunk {chunk_num} processed in {time.time()-t0:.2f} sec\")\n",
    "\n",
    "# Combine all chunks together to form one big dataframe\n",
    "agg_all = pd.concat(agg_frames, ignore_index=True).groupby('DisseminationAre', as_index=False).sum()\n",
    "\n",
    "per_naics_all = pd.concat(per_naics_frames, ignore_index=True).groupby('DisseminationAre', as_index=False).sum()\n",
    "\n",
    "business = agg_all.merge(per_naics_all, on='DisseminationAre', how='left')\n",
    "\n",
    "business = business.rename(columns={'DisseminationAre':'DA'})\n",
    "\n",
    "print(f\"\\n✅ All chunks processed in {time.time()-total_start:.2f} sec\")\n",
    "\n",
    "business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba810d-31fa-42f3-8fc0-6dffeecbc965",
   "metadata": {},
   "source": [
    "# STEP 6: Regrouping filtered data into ADAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35bc7622-0cca-43fb-98e0-b927d6e91535",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = gpd.read_file('lda_000b21a_e.shp')\n",
    "da ['DA'] = da ['DAUID']\n",
    "da ['DADGUID'] = da ['DGUID']\n",
    "da = da[['DA', 'DADGUID']]\n",
    "\n",
    "ada = gpd.read_file('lada000b21a_e.shp')\n",
    "adac = ada.copy()\n",
    "adac ['ADADGUID'] = adac ['DGUID']\n",
    "adac = adac[['ADADGUID', 'geometry']]\n",
    "\n",
    "relation = pd.read_csv('ada_da_relation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3692e0e7-199d-40e9-84f8-aca6d38fdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_relation = da.merge(relation, on='DADGUID', how='left')\n",
    "full_relation = da_relation.merge(adac, on='ADADGUID', how='left')\n",
    "full_relation['DA'] = pd.to_numeric(full_relation['DA'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad19f64e-2d38-4e91-9a8e-477e464ebc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3982846873.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  business_grouped = business_merged.groupby('ADADGUID', as_index=False).agg(**agg_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>All_Businesses</th>\n",
       "      <th>All_Employees</th>\n",
       "      <th>Auto_B</th>\n",
       "      <th>Auto_E</th>\n",
       "      <th>Alum_B</th>\n",
       "      <th>Alum_E</th>\n",
       "      <th>Steel_B</th>\n",
       "      <th>Steel_E</th>\n",
       "      <th>Cop_B</th>\n",
       "      <th>...</th>\n",
       "      <th>311821</th>\n",
       "      <th>113311</th>\n",
       "      <th>212317</th>\n",
       "      <th>326196</th>\n",
       "      <th>312110</th>\n",
       "      <th>337127</th>\n",
       "      <th>333511</th>\n",
       "      <th>311340</th>\n",
       "      <th>311615</th>\n",
       "      <th>111910</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>219</td>\n",
       "      <td>2910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>66</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>288</td>\n",
       "      <td>4186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>438</td>\n",
       "      <td>9064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>203</td>\n",
       "      <td>1441</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>11</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>13</td>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>8</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  All_Businesses  All_Employees  Auto_B  Auto_E  \\\n",
       "0     2021S051610010001             219           2910       0       0   \n",
       "1     2021S051610010002              66            394       0       0   \n",
       "2     2021S051610010003             288           4186       0       0   \n",
       "3     2021S051610010004             438           9064       0       0   \n",
       "4     2021S051610010005             203           1441       2       5   \n",
       "...                 ...             ...            ...     ...     ...   \n",
       "5428  2021S051662080004              11            356       0       0   \n",
       "5429  2021S051662080005              13            414       0       0   \n",
       "5430  2021S051662080006               8            295       0       0   \n",
       "5431  2021S051662080007               0              0       0       0   \n",
       "5432  2021S051662080008               0              0       0       0   \n",
       "\n",
       "      Alum_B  Alum_E  Steel_B  Steel_E  Cop_B  ...  311821  113311  212317  \\\n",
       "0          1       1        1        1      0  ...       0       0       0   \n",
       "1          0       0        0        0      0  ...       0       0       0   \n",
       "2          1       1        1        1      0  ...       0       0       0   \n",
       "3          1       1        1        1      1  ...       0       0       0   \n",
       "4          1       3        1        3      0  ...       0       0       0   \n",
       "...      ...     ...      ...      ...    ...  ...     ...     ...     ...   \n",
       "5428       0       0        0        0      0  ...       0       0       0   \n",
       "5429       0       0        0        0      0  ...       0       0       0   \n",
       "5430       0       0        0        0      0  ...       0       0       0   \n",
       "5431       0       0        0        0      0  ...       0       0       0   \n",
       "5432       0       0        0        0      0  ...       0       0       0   \n",
       "\n",
       "      326196  312110  337127  333511  311340  311615 111910  \n",
       "0          0       0       0       0       0       0      0  \n",
       "1          0       0       0       0       0       0      0  \n",
       "2          0       0       0       0       0       0      0  \n",
       "3          0       0       0       0       0       0      0  \n",
       "4          0       0       0       0       0       0      0  \n",
       "...      ...     ...     ...     ...     ...     ...    ...  \n",
       "5428       0       0       0       0       0       0      0  \n",
       "5429       0       0       0       0       0       0      0  \n",
       "5430       0       0       0       0       0       0      0  \n",
       "5431       0       0       0       0       0       0      0  \n",
       "5432       0       0       0       0       0       0      0  \n",
       "\n",
       "[5433 rows x 330 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_merged =(\n",
    "    business.merge(full_relation, on='DA', how='right')\n",
    "    .fillna(0)\n",
    "    .astype({col: 'int64' for col in business.columns if col != 'DA'})\n",
    ") \n",
    "\n",
    "# Group by ADADGUID and aggregate\n",
    "agg_dict = {\n",
    "    'All_Businesses': ('All_Businesses', 'sum'),\n",
    "    'All_Employees': ('All_Employees', 'sum'),\n",
    "    'Auto_B': ('Auto_B', 'sum'),\n",
    "    'Auto_E': ('Auto_E', 'sum'),\n",
    "    'Alum_B': ('Alum_B', 'sum'),\n",
    "    'Alum_E': ('Alum_E', 'sum'),\n",
    "    'Steel_B': ('Steel_B', 'sum'),\n",
    "    'Steel_E': ('Steel_E', 'sum'),\n",
    "    'Cop_B': ('Cop_B', 'sum'),\n",
    "    'Cop_E': ('Cop_E', 'sum'),\n",
    "    'Lum_B': ('Lum_B', 'sum'),\n",
    "    'Lum_E': ('Lum_E', 'sum'),\n",
    "    'Ene_B': ('Ene_B', 'sum'),\n",
    "    'Ene_E': ('Ene_E', 'sum'),\n",
    "    'CUSMA_B': ('CUSMA_B', 'sum'),\n",
    "    'CUSMA_E': ('CUSMA_E', 'sum'),\n",
    "    'Total_B': ('Total_B', 'sum'),\n",
    "    'Total_E': ('Total_E', 'sum'),\n",
    "    'geometry': ('geometry', 'first')\n",
    "}\n",
    "\n",
    "# Add dynamic aggregation rules for each NAICS code\n",
    "for naics in total_naics:\n",
    "    agg_dict[naics] = (naics, 'sum')\n",
    "\n",
    "# Perform grouped aggregation\n",
    "business_grouped = business_merged.groupby('ADADGUID', as_index=False).agg(**agg_dict)\n",
    "\n",
    "business_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52531033-7f4b-4acf-86a8-14dfc866bb3d",
   "metadata": {},
   "source": [
    "# STEP 7: Processing it into Centroids for Counts and Choropleth for Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d202b-3efd-4e51-ad51-67d4cc727ee2",
   "metadata": {},
   "source": [
    "Since the earlier table shows the *weighted* numbers of directly exposed businesses and employees (by work location) together with *total* number of employees (by work location) for each affected NAICS code, the former is separated from the latter. The former needs to be processed into separate GDFs for centroids (to show counts) and choropleths (to show percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ba63611-0a2b-4b5b-ab39-a7401b9f15fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_cols = [\n",
    "    'All_Businesses', 'All_Employees',\n",
    "    'Auto_B', 'Auto_E', 'Alum_B', 'Alum_E',\n",
    "    'Steel_B', 'Steel_E', 'Cop_B', 'Cop_E',\n",
    "    'Lum_B', 'Lum_E', 'Ene_B', 'Ene_E', \n",
    "    'CUSMA_B', 'CUSMA_E', 'Total_B', 'Total_E', \n",
    "    'geometry'\n",
    "]\n",
    "\n",
    "business_filter = business_grouped[['ADADGUID'] + [col for col in business_grouped.columns if col in excluded_cols]]\n",
    "\n",
    "business_census = business_grouped[[col for col in business_grouped.columns if col not in excluded_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b57b36a2-b77e-4eff-8a20-be2252a41ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Auto_B</th>\n",
       "      <th>Auto_E</th>\n",
       "      <th>Alum_B</th>\n",
       "      <th>Alum_E</th>\n",
       "      <th>Steel_B</th>\n",
       "      <th>Steel_E</th>\n",
       "      <th>Cop_B</th>\n",
       "      <th>Cop_E</th>\n",
       "      <th>Lum_B</th>\n",
       "      <th>Lum_E</th>\n",
       "      <th>Ene_B</th>\n",
       "      <th>Ene_E</th>\n",
       "      <th>CUSMA_B</th>\n",
       "      <th>CUSMA_E</th>\n",
       "      <th>Total_B</th>\n",
       "      <th>Total_E</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>844</td>\n",
       "      <td>16</td>\n",
       "      <td>844</td>\n",
       "      <td>POINT (8927316.642 2156398.591)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>POINT (8966678.602 2164982.461)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>54</td>\n",
       "      <td>POINT (8934606.046 2144277.889)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>POINT (8976138.327 2157799.904)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>POINT (8970965.684 2157632.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (5259010.983 3653721.631)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (6041286.124 3573109.546)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (6281761.356 3557612.071)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (5550011.303 3546406.473)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (5515075.425 3459918.304)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  Auto_B  Auto_E  Alum_B  Alum_E  Steel_B  Steel_E  \\\n",
       "0     2021S051610010001       0       0       1       1        1        1   \n",
       "1     2021S051610010002       0       0       0       0        0        0   \n",
       "2     2021S051610010003       0       0       1       1        1        1   \n",
       "3     2021S051610010004       0       0       1       1        1        1   \n",
       "4     2021S051610010005       2       5       1       3        1        3   \n",
       "...                 ...     ...     ...     ...     ...      ...      ...   \n",
       "5428  2021S051662080004       0       0       0       0        0        0   \n",
       "5429  2021S051662080005       0       0       0       0        0        0   \n",
       "5430  2021S051662080006       0       0       0       0        0        0   \n",
       "5431  2021S051662080007       0       0       0       0        0        0   \n",
       "5432  2021S051662080008       0       0       0       0        0        0   \n",
       "\n",
       "      Cop_B  Cop_E  Lum_B  Lum_E  Ene_B  Ene_E  CUSMA_B  CUSMA_E  Total_B  \\\n",
       "0         0      0      2      6      0      0       16      844       16   \n",
       "1         0      0      0      0      0      0        2       10        2   \n",
       "2         0      0      4     42      0      0        9       54        9   \n",
       "3         1      1      0      0      2     12        7       55        7   \n",
       "4         0      0      0      0      0      0        5       29        5   \n",
       "...     ...    ...    ...    ...    ...    ...      ...      ...      ...   \n",
       "5428      0      0      0      0      0      0        0        0        0   \n",
       "5429      0      0      0      0      0      0        0        0        0   \n",
       "5430      0      0      0      0      0      0        0        0        0   \n",
       "5431      0      0      0      0      0      0        0        0        0   \n",
       "5432      0      0      0      0      0      0        0        0        0   \n",
       "\n",
       "      Total_E                         geometry  \n",
       "0         844  POINT (8927316.642 2156398.591)  \n",
       "1          10  POINT (8966678.602 2164982.461)  \n",
       "2          54  POINT (8934606.046 2144277.889)  \n",
       "3          55  POINT (8976138.327 2157799.904)  \n",
       "4          29    POINT (8970965.684 2157632.7)  \n",
       "...       ...                              ...  \n",
       "5428        0  POINT (5259010.983 3653721.631)  \n",
       "5429        0  POINT (6041286.124 3573109.546)  \n",
       "5430        0  POINT (6281761.356 3557612.071)  \n",
       "5431        0  POINT (5550011.303 3546406.473)  \n",
       "5432        0  POINT (5515075.425 3459918.304)  \n",
       "\n",
       "[5433 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to GeoDataFrame\n",
    "cent_gdf = gpd.GeoDataFrame(business_filter, geometry='geometry', crs = 'EPSG:3347')\n",
    "\n",
    "# Set a point within each polygon\n",
    "cent_gdf = cent_gdf.drop(columns=['All_Businesses', 'All_Employees'])\n",
    "cent_gdf['geometry'] = cent_gdf.geometry.representative_point()\n",
    "cent_gdf.set_geometry('geometry', inplace=True)\n",
    "cent_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f018d8-0a4d-4ee3-ac34-aefbf0a1fc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Auto_1</th>\n",
       "      <th>Alum_1</th>\n",
       "      <th>Steel_1</th>\n",
       "      <th>Cop_1</th>\n",
       "      <th>Lum_1</th>\n",
       "      <th>Ene_1</th>\n",
       "      <th>CUSMA_1</th>\n",
       "      <th>Total_1</th>\n",
       "      <th>Auto_2</th>\n",
       "      <th>Alum_2</th>\n",
       "      <th>Steel_2</th>\n",
       "      <th>Cop_2</th>\n",
       "      <th>Lum_2</th>\n",
       "      <th>Ene_2</th>\n",
       "      <th>CUSMA_2</th>\n",
       "      <th>Total_2</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290034</td>\n",
       "      <td>0.290034</td>\n",
       "      <td>MULTIPOLYGON (((8921559.157 2130255.903, 89215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>POLYGON ((8959571.943 2171799.486, 8959576.689...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>MULTIPOLYGON (((8938088.457 2157739.16, 893808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>POLYGON ((8976008.48 2163749.357, 8976015.274 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.00347</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>POLYGON ((8969716.249 2163377.051, 8969785.883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((5263454.031 3662224.177, 52634...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((6043125.089 3568426.163, 60431...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((6280121.289 3558103.571, 62801...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((5544792.883 3549525.897, 55447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((5516884.22 3462631.751, 551687...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID    Auto_1    Alum_1   Steel_1     Cop_1     Lum_1  \\\n",
       "0     2021S051610010001  0.000000  0.004566  0.004566  0.000000  0.009132   \n",
       "1     2021S051610010002  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     2021S051610010003  0.000000  0.003472  0.003472  0.000000  0.013889   \n",
       "3     2021S051610010004  0.000000  0.002283  0.002283  0.002283  0.000000   \n",
       "4     2021S051610010005  0.009852  0.004926  0.004926  0.000000  0.000000   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "5428  2021S051662080004  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5429  2021S051662080005  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5430  2021S051662080006  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5431  2021S051662080007       NaN       NaN       NaN       NaN       NaN   \n",
       "5432  2021S051662080008       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "         Ene_1   CUSMA_1   Total_1   Auto_2    Alum_2   Steel_2    Cop_2  \\\n",
       "0     0.000000  0.073059  0.073059  0.00000  0.000344  0.000344  0.00000   \n",
       "1     0.000000  0.030303  0.030303  0.00000  0.000000  0.000000  0.00000   \n",
       "2     0.000000  0.031250  0.031250  0.00000  0.000239  0.000239  0.00000   \n",
       "3     0.004566  0.015982  0.015982  0.00000  0.000110  0.000110  0.00011   \n",
       "4     0.000000  0.024631  0.024631  0.00347  0.002082  0.002082  0.00000   \n",
       "...        ...       ...       ...      ...       ...       ...      ...   \n",
       "5428  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "5429  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "5430  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "5431       NaN       NaN       NaN      NaN       NaN       NaN      NaN   \n",
       "5432       NaN       NaN       NaN      NaN       NaN       NaN      NaN   \n",
       "\n",
       "         Lum_2     Ene_2   CUSMA_2   Total_2  \\\n",
       "0     0.002062  0.000000  0.290034  0.290034   \n",
       "1     0.000000  0.000000  0.025381  0.025381   \n",
       "2     0.010033  0.000000  0.012900  0.012900   \n",
       "3     0.000000  0.001324  0.006068  0.006068   \n",
       "4     0.000000  0.000000  0.020125  0.020125   \n",
       "...        ...       ...       ...       ...   \n",
       "5428  0.000000  0.000000  0.000000  0.000000   \n",
       "5429  0.000000  0.000000  0.000000  0.000000   \n",
       "5430  0.000000  0.000000  0.000000  0.000000   \n",
       "5431       NaN       NaN       NaN       NaN   \n",
       "5432       NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                               geometry  \n",
       "0     MULTIPOLYGON (((8921559.157 2130255.903, 89215...  \n",
       "1     POLYGON ((8959571.943 2171799.486, 8959576.689...  \n",
       "2     MULTIPOLYGON (((8938088.457 2157739.16, 893808...  \n",
       "3     POLYGON ((8976008.48 2163749.357, 8976015.274 ...  \n",
       "4     POLYGON ((8969716.249 2163377.051, 8969785.883...  \n",
       "...                                                 ...  \n",
       "5428  MULTIPOLYGON (((5263454.031 3662224.177, 52634...  \n",
       "5429  MULTIPOLYGON (((6043125.089 3568426.163, 60431...  \n",
       "5430  MULTIPOLYGON (((6280121.289 3558103.571, 62801...  \n",
       "5431  MULTIPOLYGON (((5544792.883 3549525.897, 55447...  \n",
       "5432  MULTIPOLYGON (((5516884.22 3462631.751, 551687...  \n",
       "\n",
       "[5433 rows x 18 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choro_cols = business_filter.copy()\n",
    "\n",
    "tars = ['Auto', 'Alum', 'Steel', 'Cop', 'Lum', 'Ene', 'CUSMA', 'Total']\n",
    "\n",
    "for tar in tars:\n",
    "    tar_1 = f'{tar}_1'\n",
    "    tar_2 = f'{tar}_2'\n",
    "\n",
    "    choro_cols[tar_1] = (\n",
    "        choro_cols[f'{tar}_B']/choro_cols['All_Businesses']\n",
    "    )\n",
    "\n",
    "    choro_cols[tar_2] = (\n",
    "        choro_cols[f'{tar}_E']/choro_cols['All_Employees']\n",
    "    )\n",
    "\n",
    "choro_cols = choro_cols[['ADADGUID'] + [f'{tar}_1' for tar in tars] + [f'{tar}_2' for tar in tars] + ['geometry']]\n",
    "\n",
    "choro_gdf = gpd.GeoDataFrame(choro_cols, geometry = 'geometry', crs = 'EPSG:3347')\n",
    "choro_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7802b6-9d94-4938-b399-e8b54e6de279",
   "metadata": {},
   "source": [
    "# STEP 8: Generating Weight of Directly Exposed Jobs to Total Accessible Jobs in Each Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5543a3-382b-41fb-84b5-890700d7b60c",
   "metadata": {},
   "source": [
    "It is likely that while employees live close to their workplace, they do not live in the same ADA as they work in.  \n",
    "  \n",
    "StatsCan Census 2021 data shows a huge drop in the number of Canadians who travel more than 15km to their work vis-a-vis those who travel less than that distance to work.  \n",
    "  \n",
    "Thus, this cell creates a dictionary where for each ADA, it lists down, including itself, the ADA IDs within a 15km buffer around it (for small ADAs) or ADA IDs that are adjacent to it (for large ADAs). Small ADAs are defined as ADAs with an area less than (15km)^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7087f7bf-537e-4017-9640-0a05f178b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▌                                                                           | 1/11 [00:33<05:33, 33.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0-500 processed in 0:00:33.331829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████                                                                    | 2/11 [00:36<02:20, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 500-1000 processed in 0:00:03.165345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████▋                                                            | 3/11 [00:40<01:21, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1000-1500 processed in 0:00:03.735485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▏                                                    | 4/11 [01:15<02:21, 20.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1500-2000 processed in 0:00:35.592571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▋                                             | 5/11 [01:18<01:23, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2000-2500 processed in 0:00:02.955679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████▎                                     | 6/11 [02:19<02:28, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2500-3000 processed in 0:01:00.229061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████▊                              | 7/11 [02:33<01:39, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3000-3500 processed in 0:00:14.841341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [02:35<00:52, 17.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3500-4000 processed in 0:00:02.086795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [02:37<00:25, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4000-4500 processed in 0:00:02.035073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 10/11 [02:46<00:11, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4500-5000 processed in 0:00:08.623929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [05:14<00:00, 28.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 5000-5433 processed in 0:02:28.334659\n",
      "\n",
      "Total time taken: 0:05:14.984763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Copy from earlier ADA shapefile and ensure it's in projected CRS (EPSG:3347)\n",
    "adas = ada.to_crs(\"EPSG:3347\")\n",
    "\n",
    "# Create a column to mark if ADA is \"small\" (<= 706 km2)\n",
    "adas['is_small'] = adas['LANDAREA'] <= 706\n",
    "\n",
    "# Build spatial index once\n",
    "adas_sindex = adas.sindex\n",
    "\n",
    "# Simplify geometries early to reduce memory use\n",
    "adas['geometry'] = adas['geometry'].simplify(100)\n",
    "\n",
    "# Prepare empty dictionary\n",
    "ada_neighbors = {}\n",
    "\n",
    "# Process in chunks to avoid RAM overload\n",
    "chunk_size = 500\n",
    "n = len(adas)\n",
    "\n",
    "# Track overall time\n",
    "start_time = time.time()\n",
    "\n",
    "for start in tqdm(range(0, n, chunk_size)):\n",
    "    chunk_start_time = time.time()\n",
    "    end = min(start + chunk_size, n)\n",
    "    chunk = adas.iloc[start:end].copy()\n",
    "\n",
    "    for idx, row in chunk.iterrows():\n",
    "        ada_uid = row['DGUID']\n",
    "        geom = row['geometry']\n",
    "        is_small = row['is_small']\n",
    "\n",
    "        if is_small:\n",
    "            buffer_geom = geom.buffer(15000)\n",
    "            possible_matches_index = list(adas_sindex.intersection(buffer_geom.bounds))\n",
    "            possible_matches = adas.iloc[possible_matches_index]\n",
    "            matches = possible_matches[possible_matches.geometry.intersects(buffer_geom)]\n",
    "        else:\n",
    "            possible_matches_index = list(adas_sindex.intersection(geom.bounds))\n",
    "            possible_matches = adas.iloc[possible_matches_index]\n",
    "            matches = possible_matches[possible_matches.geometry.touches(geom) | (possible_matches['DGUID'] == ada_uid)]\n",
    "\n",
    "        ada_neighbors[ada_uid] = matches['DGUID'].tolist()\n",
    "\n",
    "    del chunk\n",
    "    gc.collect()\n",
    "\n",
    "    # Print chunk timing\n",
    "    chunk_elapsed = time.time() - chunk_start_time\n",
    "    print(f\"Chunk {start}-{end} processed in {timedelta(seconds=chunk_elapsed)}\")\n",
    "\n",
    "# Overall timing\n",
    "total_elapsed = time.time() - start_time\n",
    "print(f\"\\nTotal time taken: {timedelta(seconds=total_elapsed)}\")\n",
    "\n",
    "# Optionally save the dictionary to disk\n",
    "with open(\"ada_neighbors.json\", \"w\") as f:\n",
    "    json.dump(ada_neighbors, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841738d-8e78-40e3-a8b7-a2f120eea5f7",
   "metadata": {},
   "source": [
    "The dictionary is then used in conjunction with the *total* count of employees (by work location), as separated in Cell 13 above, to find out the likely number of jobs of each 6-digit NAICS, and total number of jobs, that are 'accessible' from each ADA --> going by the assumption of travel distance made by Canadians to go to work from Census 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89928d72-34aa-4064-9f8d-abcc4df05247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5433/5433 [00:07<00:00, 728.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'ADADGUID' is the index for fast lookup\n",
    "business_census_indexed = business_census.set_index('ADADGUID')\n",
    "\n",
    "# Prepare list to collect results\n",
    "aggregated_results = []\n",
    "\n",
    "# Loop through ADA + its neighbors\n",
    "for ada_id, neighbor_list in tqdm(ada_neighbors.items()):\n",
    "    # Filter business_census rows for all neighbors\n",
    "    rows = business_census_indexed.loc[business_census_indexed.index.intersection(neighbor_list)]\n",
    "    \n",
    "    # Sum across all rows (by column)\n",
    "    summed = rows.sum()\n",
    "    \n",
    "    # Store result with ADA ID\n",
    "    result = summed.to_dict()\n",
    "    result['ADADGUID'] = ada_id\n",
    "    \n",
    "    aggregated_results.append(result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "jobs = pd.DataFrame(aggregated_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b623b-bad5-4aaf-a96d-f274d89c3eb5",
   "metadata": {},
   "source": [
    "This is to find out the rate of directly exposed jobs (6-digit NAICS) to total jobs in each industry (1-digit NAICS jobs) that are accessible from each ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5315dd5f-23f8-4972-aded-e58033b28780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\3702249403.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>332329_R</th>\n",
       "      <th>334290_R</th>\n",
       "      <th>332431_R</th>\n",
       "      <th>331221_R</th>\n",
       "      <th>334220_R</th>\n",
       "      <th>336611_R</th>\n",
       "      <th>212397_R</th>\n",
       "      <th>331110_R</th>\n",
       "      <th>312140_R</th>\n",
       "      <th>...</th>\n",
       "      <th>311821_R</th>\n",
       "      <th>113311_R</th>\n",
       "      <th>212317_R</th>\n",
       "      <th>326196_R</th>\n",
       "      <th>312110_R</th>\n",
       "      <th>337127_R</th>\n",
       "      <th>333511_R</th>\n",
       "      <th>311340_R</th>\n",
       "      <th>311615_R</th>\n",
       "      <th>111910_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.054936</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093684</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.054936</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093684</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  332329_R  334290_R  332431_R  331221_R  334220_R  \\\n",
       "0     2021S051610010001  0.000000       0.0       0.0       0.0       0.0   \n",
       "1     2021S051610010002  0.002472       0.0       0.0       0.0       0.0   \n",
       "2     2021S051610010003  0.000000       0.0       0.0       0.0       0.0   \n",
       "3     2021S051610010004  0.001858       0.0       0.0       0.0       0.0   \n",
       "4     2021S051610010005  0.001858       0.0       0.0       0.0       0.0   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "5428  2021S051662080004  0.000000       0.0       0.0       0.0       0.0   \n",
       "5429  2021S051662080005  0.000000       0.0       0.0       0.0       0.0   \n",
       "5430  2021S051662080006  0.000000       0.0       0.0       0.0       0.0   \n",
       "5431  2021S051662080007  0.000000       0.0       0.0       0.0       0.0   \n",
       "5432  2021S051662080008  0.000000       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      336611_R  212397_R  331110_R  312140_R  ...  311821_R  113311_R  \\\n",
       "0     0.000000       0.0       0.0  0.000000  ...  0.000000       0.0   \n",
       "1     0.123588       0.0       0.0  0.013418  ...  0.026483       0.0   \n",
       "2     0.004372       0.0       0.0  0.010201  ...  0.000000       0.0   \n",
       "3     0.102176       0.0       0.0  0.010085  ...  0.019904       0.0   \n",
       "4     0.102176       0.0       0.0  0.010085  ...  0.019904       0.0   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "5428  0.000000       0.0       0.0  0.000000  ...  0.000000       0.0   \n",
       "5429  0.000000       0.0       0.0  0.000000  ...  0.000000       0.0   \n",
       "5430  0.000000       0.0       0.0  0.000000  ...  0.000000       0.0   \n",
       "5431  0.000000       0.0       0.0  0.000000  ...  0.000000       0.0   \n",
       "5432  0.000000       0.0       0.0  0.000000  ...  0.000000       0.0   \n",
       "\n",
       "      212317_R  326196_R  312110_R  337127_R  333511_R  311340_R  311615_R  \\\n",
       "0          0.0  0.000000  0.000000  0.000000       0.0       0.0  0.000000   \n",
       "1          0.0  0.000000  0.067797  0.000000       0.0       0.0  0.124647   \n",
       "2          0.0  0.000000  0.000000  0.000000       0.0       0.0  0.000000   \n",
       "3          0.0  0.019904  0.054936  0.001858       0.0       0.0  0.093684   \n",
       "4          0.0  0.019904  0.054936  0.001858       0.0       0.0  0.093684   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5428       0.0  0.000000  0.000000  0.000000       0.0       0.0  0.000000   \n",
       "5429       0.0  0.000000  0.000000  0.000000       0.0       0.0  0.000000   \n",
       "5430       0.0  0.000000  0.000000  0.000000       0.0       0.0  0.000000   \n",
       "5431       0.0  0.000000  0.000000  0.000000       0.0       0.0  0.000000   \n",
       "5432       0.0  0.000000  0.000000  0.000000       0.0       0.0  0.000000   \n",
       "\n",
       "      111910_R  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "5428       0.0  \n",
       "5429       0.0  \n",
       "5430       0.0  \n",
       "5431       0.0  \n",
       "5432       0.0  \n",
       "\n",
       "[5433 rows x 311 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_rate = jobs.copy()\n",
    "\n",
    "cola = [col for col in jobs.columns if col != 'ADADGUID']\n",
    "\n",
    "# Calculate summed groups by first digit of column name\n",
    "jobs_rate['Sum1'] = jobs_rate[[col for col in cola if col.startswith('1')]].sum(axis=1)\n",
    "jobs_rate['Sum2'] = jobs_rate[[col for col in cola if col.startswith('2')]].sum(axis=1)\n",
    "jobs_rate['Sum3'] = jobs_rate[[col for col in cola if col.startswith('3')]].sum(axis=1)\n",
    "\n",
    "# Compute share per column\n",
    "for col in cola:\n",
    "    col_rate = f'{col}_R'\n",
    "    if col.startswith('1'):\n",
    "        jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum1']\n",
    "    elif col.startswith('2'):\n",
    "        jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum2']\n",
    "    elif col.startswith('3'):\n",
    "        jobs_rate[col_rate] = jobs_rate[col] / jobs_rate['Sum3']\n",
    "    else:\n",
    "        jobs_rate[col_rate] = 0  # fallback in case of unexpected prefix\n",
    "\n",
    "# Final filtered DataFrame: only ADADGUID and the *_R columns\n",
    "jobs_rate = jobs_rate[['ADADGUID'] + [f'{col}_R' for col in cola]]\n",
    "\n",
    "jobs_rate = jobs_rate.fillna(0)\n",
    "\n",
    "jobs_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37308b-3570-44a3-a6de-d493c61782e3",
   "metadata": {},
   "source": [
    "# STEP 9: Applying Jobs Weight to Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e93621-6a33-436c-be5c-7344ca76e3de",
   "metadata": {},
   "source": [
    "Census 2021 Data reports residents' occupational NAICS code at the two-digit level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb473b54-6e12-4e46-bdd2-d98a29a8cbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CHARACTERISTIC_NAME</th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Province</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>To</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>NL</td>\n",
       "      <td>455.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>3715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>NL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>NL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>4530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>NL</td>\n",
       "      <td>20.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>NL</td>\n",
       "      <td>35.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>2021S051662080002</td>\n",
       "      <td>NU</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>2021S051662080003</td>\n",
       "      <td>NU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>NU</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>NU</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>NU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4962 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "CHARACTERISTIC_NAME           ADADGUID Province     11     21     31      To\n",
       "0                    2021S051610010001       NL  455.0  120.0  665.0  3715.0\n",
       "1                    2021S051610010002       NL   50.0   70.0   60.0  2120.0\n",
       "2                    2021S051610010003       NL  160.0  100.0  310.0  4530.0\n",
       "3                    2021S051610010004       NL   20.0  170.0  130.0  5145.0\n",
       "4                    2021S051610010005       NL   35.0  215.0  130.0  5190.0\n",
       "...                                ...      ...    ...    ...    ...     ...\n",
       "4957                 2021S051662080002       NU   10.0   15.0   10.0   860.0\n",
       "4958                 2021S051662080003       NU    0.0    0.0    0.0   210.0\n",
       "4959                 2021S051662080004       NU   10.0    0.0    0.0   510.0\n",
       "4960                 2021S051662080005       NU   10.0   10.0    0.0   465.0\n",
       "4961                 2021S051662080006       NU    0.0    0.0    0.0   280.0\n",
       "\n",
       "[4962 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census = pd.read_csv('98-401-X2021012_English_CSV_data.csv', encoding='latin1')\n",
    "\n",
    "census = census[census['CHARACTERISTIC_ID'].isin([2259, 2262, 2263, 2266])] # Only taking the relevant 2-digit NAICS codes from Census 2021 data\n",
    "\n",
    "census['ADADGUID'] = census['DGUID']\n",
    "\n",
    "census['ProvinceCode'] = census['ADADGUID'].str[9:11].astype(int)\n",
    "\n",
    "census['Province'] = census['ProvinceCode'].map(province_code)\n",
    "\n",
    "census['CHARACTERISTIC_NAME'] = (\n",
    "    census['CHARACTERISTIC_NAME']\n",
    "    .str.replace(' ', '', regex=False)\n",
    "    .str[:2]\n",
    ")\n",
    "\n",
    "census = census[['ADADGUID', 'Province', 'CHARACTERISTIC_NAME', 'C1_COUNT_TOTAL']]\n",
    "\n",
    "census_pivot = census.pivot_table(\n",
    "    index=['ADADGUID', 'Province'],\n",
    "    columns='CHARACTERISTIC_NAME',\n",
    "    values='C1_COUNT_TOTAL',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "census_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1defe9-ea10-4d5b-86f7-c9abf0cbf776",
   "metadata": {},
   "source": [
    "Thus the weights from Step 8 is used to estimate how many employees (by primary residence) are working in industries directly exposed to tariffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "368f4477-8730-4609-ba8d-4e4f4ab48640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
      "C:\\Users\\mkbs_\\AppData\\Local\\Temp\\ipykernel_16980\\2488107975.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  adjusted_jobs['Sum'] = adjusted_jobs.drop(columns=['ADADGUID', 'Province', 'To']).sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Province</th>\n",
       "      <th>To</th>\n",
       "      <th>332329</th>\n",
       "      <th>334290</th>\n",
       "      <th>332431</th>\n",
       "      <th>331221</th>\n",
       "      <th>334220</th>\n",
       "      <th>336611</th>\n",
       "      <th>212397</th>\n",
       "      <th>...</th>\n",
       "      <th>113311</th>\n",
       "      <th>212317</th>\n",
       "      <th>326196</th>\n",
       "      <th>312110</th>\n",
       "      <th>337127</th>\n",
       "      <th>333511</th>\n",
       "      <th>311340</th>\n",
       "      <th>311615</th>\n",
       "      <th>111910</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>NL</td>\n",
       "      <td>3715.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>NL</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>NL</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>NL</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>NL</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>437.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>NU</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>NU</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>NU</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>NU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>NU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID Province      To  332329  334290  332431  331221  \\\n",
       "0     2021S051610010001       NL  3715.0     0.0     0.0     0.0     0.0   \n",
       "1     2021S051610010002       NL  2120.0     1.0     0.0     0.0     0.0   \n",
       "2     2021S051610010003       NL  4530.0     0.0     0.0     0.0     0.0   \n",
       "3     2021S051610010004       NL  5145.0     1.0     0.0     0.0     0.0   \n",
       "4     2021S051610010005       NL  5190.0     1.0     0.0     0.0     0.0   \n",
       "...                 ...      ...     ...     ...     ...     ...     ...   \n",
       "5428  2021S051662080004       NU   510.0     0.0     0.0     0.0     0.0   \n",
       "5429  2021S051662080005       NU   465.0     0.0     0.0     0.0     0.0   \n",
       "5430  2021S051662080006       NU   280.0     0.0     0.0     0.0     0.0   \n",
       "5431  2021S051662080007       NU     0.0     0.0     0.0     0.0     0.0   \n",
       "5432  2021S051662080008       NU     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      334220  336611  212397  ...  113311  212317  326196  312110  337127  \\\n",
       "0        0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "1        0.0     8.0     0.0  ...     0.0     0.0     0.0     5.0     0.0   \n",
       "2        0.0     2.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "3        0.0    14.0     0.0  ...     0.0     0.0     3.0     8.0     1.0   \n",
       "4        0.0    14.0     0.0  ...     0.0     0.0     3.0     8.0     1.0   \n",
       "...      ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "5428     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5429     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5430     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5431     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "5432     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      333511  311340  311615  111910     Sum  \n",
       "0        0.0     0.0     0.0     0.0  1129.0  \n",
       "1        0.0     0.0     8.0     0.0   225.0  \n",
       "2        0.0     0.0     0.0     0.0   590.0  \n",
       "3        0.0     0.0    13.0     0.0   379.0  \n",
       "4        0.0     0.0    13.0     0.0   437.0  \n",
       "...      ...     ...     ...     ...     ...  \n",
       "5428     0.0     0.0     0.0     0.0     0.0  \n",
       "5429     0.0     0.0     0.0     0.0     0.0  \n",
       "5430     0.0     0.0     0.0     0.0     0.0  \n",
       "5431     0.0     0.0     0.0     0.0     0.0  \n",
       "5432     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5433 rows x 314 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge on ADADGUID to align both datasets\n",
    "merged = census_pivot.merge(jobs_rate, on='ADADGUID', how='right')  # or 'left' if census is base\n",
    "\n",
    "# Start building the adjusted DataFrame\n",
    "adjusted_jobs = merged[['ADADGUID', 'Province', 'To']].copy()\n",
    "\n",
    "# Compute adjusted values\n",
    "for col in cola:\n",
    "    rate_col = f'{col}_R'\n",
    "    prefix = col[:2]\n",
    "\n",
    "    if prefix in ['21', '22']:\n",
    "        source_col = '21'\n",
    "    elif prefix in ['31', '32', '33']:\n",
    "        source_col = '31'\n",
    "    else:\n",
    "        source_col = prefix\n",
    "\n",
    "    adjusted_jobs[col] = np.ceil(merged[rate_col] * merged[source_col])\n",
    "\n",
    "adjusted_jobs['Sum'] = adjusted_jobs.drop(columns=['ADADGUID', 'Province', 'To']).sum(axis=1)\n",
    "\n",
    "adjusted_jobs = adjusted_jobs.fillna(0)\n",
    "\n",
    "adjusted_jobs['Province'] = adjusted_jobs['Province'].mask(\n",
    "    adjusted_jobs['Province'].isin([0, np.nan]),\n",
    "    adjusted_jobs['ADADGUID'].str[9:11].astype(int).map(province_code)\n",
    ")\n",
    "\n",
    "adjusted_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38222000-ec1c-4690-b257-684257b37c00",
   "metadata": {},
   "source": [
    "# STEP 10: Applying Export Weights to the Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b57b0f-8436-4df5-af3a-3f7ae6e02e8c",
   "metadata": {},
   "source": [
    "Export weights from Step 4 are applied to account for regional differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27a70d30-d89b-40bb-91ea-d09ea2766c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NAICS</th>\n",
       "      <th>Province</th>\n",
       "      <th>111110_r</th>\n",
       "      <th>111120_r</th>\n",
       "      <th>111130_r</th>\n",
       "      <th>111140_r</th>\n",
       "      <th>111150_r</th>\n",
       "      <th>111160_r</th>\n",
       "      <th>111190_r</th>\n",
       "      <th>111211_r</th>\n",
       "      <th>111219_r</th>\n",
       "      <th>...</th>\n",
       "      <th>337215_r</th>\n",
       "      <th>337910_r</th>\n",
       "      <th>337920_r</th>\n",
       "      <th>339110_r</th>\n",
       "      <th>339910_r</th>\n",
       "      <th>339920_r</th>\n",
       "      <th>339930_r</th>\n",
       "      <th>339940_r</th>\n",
       "      <th>339950_r</th>\n",
       "      <th>339990_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032376</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981173</td>\n",
       "      <td>0.514049</td>\n",
       "      <td>0.213624</td>\n",
       "      <td>0.532096</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.663320</td>\n",
       "      <td>0.368632</td>\n",
       "      <td>0.720095</td>\n",
       "      <td>0.206830</td>\n",
       "      <td>0.425631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>0.243865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851043</td>\n",
       "      <td>0.186107</td>\n",
       "      <td>0.213990</td>\n",
       "      <td>0.590677</td>\n",
       "      <td>0.746073</td>\n",
       "      <td>0.587708</td>\n",
       "      <td>0.255254</td>\n",
       "      <td>0.691042</td>\n",
       "      <td>0.265313</td>\n",
       "      <td>0.269257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB</td>\n",
       "      <td>0.064938</td>\n",
       "      <td>0.094353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030494</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888928</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.131253</td>\n",
       "      <td>0.450144</td>\n",
       "      <td>0.332359</td>\n",
       "      <td>0.582863</td>\n",
       "      <td>0.337235</td>\n",
       "      <td>0.859608</td>\n",
       "      <td>0.151730</td>\n",
       "      <td>0.573977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.124930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795159</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.205144</td>\n",
       "      <td>0.849244</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.243381</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.831198</td>\n",
       "      <td>0.699527</td>\n",
       "      <td>0.330572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416990</td>\n",
       "      <td>0.268019</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>0.358952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703223</td>\n",
       "      <td>0.786739</td>\n",
       "      <td>0.706480</td>\n",
       "      <td>0.397013</td>\n",
       "      <td>0.049719</td>\n",
       "      <td>0.149934</td>\n",
       "      <td>0.471560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NU</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NWT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ON</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>0.371635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032567</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.315716</td>\n",
       "      <td>0.206290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948650</td>\n",
       "      <td>0.728146</td>\n",
       "      <td>0.187830</td>\n",
       "      <td>0.555835</td>\n",
       "      <td>0.907276</td>\n",
       "      <td>0.653166</td>\n",
       "      <td>0.248730</td>\n",
       "      <td>0.732703</td>\n",
       "      <td>0.562703</td>\n",
       "      <td>0.597974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PEI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.227019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.485059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QC</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045639</td>\n",
       "      <td>0.194542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932103</td>\n",
       "      <td>0.757829</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.687646</td>\n",
       "      <td>0.884357</td>\n",
       "      <td>0.808154</td>\n",
       "      <td>0.347140</td>\n",
       "      <td>0.467514</td>\n",
       "      <td>0.748507</td>\n",
       "      <td>0.464566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SK</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.047928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.314639</td>\n",
       "      <td>0.840800</td>\n",
       "      <td>0.866177</td>\n",
       "      <td>0.409485</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.604759</td>\n",
       "      <td>0.349298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>YK</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NAICS Province  111110_r  111120_r  111130_r  111140_r  111150_r  111160_r  \\\n",
       "0           AL  0.024138  0.034204       0.0  0.032376  0.370000  0.000000   \n",
       "1           BC  0.000000  0.028733       0.0  0.028748  0.243865  0.000000   \n",
       "2           MB  0.064938  0.094353       0.0  0.030494  0.370000  0.000000   \n",
       "3           NB  0.620000  0.124930       0.0  0.620000  0.000000  0.000000   \n",
       "4           NL  0.000000  0.620000       0.0  0.000000  0.000000  0.000000   \n",
       "5           NS  0.000000  0.000000       0.0  0.620000  0.000000  0.000000   \n",
       "6           NU  0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "7          NWT  0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "8           ON  0.057076  0.371635       0.0  0.032567  0.074227  0.315716   \n",
       "9          PEI  0.000000  0.620000       0.0  0.000000  0.000000  0.000000   \n",
       "10          QC  0.016695  0.039934       0.0  0.045639  0.194542  0.000000   \n",
       "11          SK  0.000728  0.047928       0.0  0.038389  0.000000  0.000000   \n",
       "12          YK  0.000000  0.000000       0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "NAICS  111190_r  111211_r  111219_r  ...  337215_r  337910_r  337920_r  \\\n",
       "0      0.117974       0.0  0.026535  ...  0.981173  0.514049  0.213624   \n",
       "1      0.156439       0.0  0.000031  ...  0.851043  0.186107  0.213990   \n",
       "2      0.264963       0.0  0.127486  ...  0.888928  0.790000  0.131253   \n",
       "3      0.000000       0.0  0.004048  ...  0.795159  0.790000  0.205144   \n",
       "4      0.000000       0.0  0.000000  ...  0.956908  0.000000  0.000000   \n",
       "5      0.000000       0.0  0.000000  ...  0.905935  0.000000  0.000000   \n",
       "6      0.000000       0.0  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "7      0.000000       0.0  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "8      0.206290       0.0  0.001356  ...  0.948650  0.728146  0.187830   \n",
       "9      0.370000       0.0  0.000000  ...  0.106944  0.000000  0.000000   \n",
       "10     0.180804       0.0  0.000226  ...  0.932103  0.757829  0.097168   \n",
       "11     0.155096       0.0  0.001149  ...  0.990590  0.000000  0.107843   \n",
       "12     0.000000       0.0  0.000000  ...  0.896739  0.000000  0.000000   \n",
       "\n",
       "NAICS  339110_r  339910_r  339920_r  339930_r  339940_r  339950_r  339990_r  \n",
       "0      0.532096  0.529703  0.663320  0.368632  0.720095  0.206830  0.425631  \n",
       "1      0.590677  0.746073  0.587708  0.255254  0.691042  0.265313  0.269257  \n",
       "2      0.450144  0.332359  0.582863  0.337235  0.859608  0.151730  0.573977  \n",
       "3      0.849244  0.890000  0.243381  0.420000  0.831198  0.699527  0.330572  \n",
       "4      0.416990  0.268019  0.079019  0.358952  0.000000  0.000000  0.132630  \n",
       "5      0.703223  0.786739  0.706480  0.397013  0.049719  0.149934  0.471560  \n",
       "6      0.870000  0.890000  0.000000  0.420000  0.000000  0.150000  0.240000  \n",
       "7      0.000000  0.890000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "8      0.555835  0.907276  0.653166  0.248730  0.732703  0.562703  0.597974  \n",
       "9      0.000000  0.890000  0.227019  0.000000  0.000000  0.150000  0.485059  \n",
       "10     0.687646  0.884357  0.808154  0.347140  0.467514  0.748507  0.464566  \n",
       "11     0.314639  0.840800  0.866177  0.409485  0.150000  0.604759  0.349298  \n",
       "12     0.870000  0.890000  1.000000  0.000000  0.000000  0.150000  0.870000  \n",
       "\n",
       "[13 rows x 311 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Melt to long format\n",
    "long_weight = weight_naics.melt(id_vars='NAICS', var_name='Province', value_name='Rate')\n",
    "\n",
    "long_weight['NAICS'] = long_weight['NAICS'].astype(str) + '_r'\n",
    "\n",
    "# Step 2: Pivot to wide format\n",
    "weight_naics_pivot = long_weight.pivot(index=['Province'], columns='NAICS', values='Rate').reset_index()\n",
    "\n",
    "weight_naics_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a289acfa-a7f2-4449-9621-078398572828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Census</th>\n",
       "      <th>Auto_C</th>\n",
       "      <th>Alum_C</th>\n",
       "      <th>Steel_C</th>\n",
       "      <th>Cop_C</th>\n",
       "      <th>Lum_C</th>\n",
       "      <th>Ene_C</th>\n",
       "      <th>CUSMA_C</th>\n",
       "      <th>Total_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>3715.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  Census  Auto_C  Alum_C  Steel_C  Cop_C  Lum_C  Ene_C  \\\n",
       "0     2021S051610010001  3715.0     0.0     1.0      1.0    0.0    5.0    0.0   \n",
       "1     2021S051610010002  2120.0     6.0     8.0      8.0    1.0    3.0    7.0   \n",
       "2     2021S051610010003  4530.0     0.0     1.0      2.0    0.0    8.0   28.0   \n",
       "3     2021S051610010004  5145.0     6.0     9.0      8.0    1.0    4.0   13.0   \n",
       "4     2021S051610010005  5190.0     6.0     9.0      8.0    1.0    4.0   15.0   \n",
       "...                 ...     ...     ...     ...      ...    ...    ...    ...   \n",
       "5428  2021S051662080004   510.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "5429  2021S051662080005   465.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "5430  2021S051662080006   280.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "5431  2021S051662080007     0.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "5432  2021S051662080008     0.0     0.0     0.0      0.0    0.0    0.0    0.0   \n",
       "\n",
       "      CUSMA_C  Total_C  \n",
       "0       613.0    613.0  \n",
       "1        82.0     82.0  \n",
       "2       258.0    258.0  \n",
       "3        95.0     95.0  \n",
       "4       107.0    107.0  \n",
       "...       ...      ...  \n",
       "5428      0.0      0.0  \n",
       "5429      0.0      0.0  \n",
       "5430      0.0      0.0  \n",
       "5431      0.0      0.0  \n",
       "5432      0.0      0.0  \n",
       "\n",
       "[5433 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Merge adjusted_jobs with weight_naics_pivot on Province\n",
    "census_byjobs = adjusted_jobs.merge(weight_naics_pivot, on='Province', how='left')\n",
    "\n",
    "# Step 2: Multiply each column by its corresponding rate\n",
    "for col in cola:\n",
    "    rate_col = f'{col}_r'\n",
    "    \n",
    "    census_byjobs[col] = np.ceil(census_byjobs[col] * census_byjobs[rate_col])\n",
    "\n",
    "# Step 3: Keep only ADADGUID and updated values\n",
    "census_byjobs = census_byjobs[['ADADGUID', 'To'] + cola]\n",
    "\n",
    "# Define output dictionary\n",
    "grouped_data = {\n",
    "    'ADADGUID': census_byjobs['ADADGUID'],  # retain ADA ID\n",
    "    'Census': census_byjobs['To'],\n",
    "    'Auto_C': census_byjobs[[col for col in cola if col in auto_naics]].sum(axis=1),\n",
    "    'Alum_C': census_byjobs[[col for col in cola if col in alum_naics]].sum(axis=1),\n",
    "    'Steel_C': census_byjobs[[col for col in cola if col in steel_naics]].sum(axis=1),\n",
    "    'Cop_C': census_byjobs[[col for col in cola if col in copper_naics]].sum(axis=1),\n",
    "    'Lum_C': census_byjobs[[col for col in cola if col in lum_naics]].sum(axis=1),\n",
    "    'Ene_C': census_byjobs[[col for col in cola if col in ene_naics]].sum(axis=1),\n",
    "    'CUSMA_C': census_byjobs[[col for col in cola if col in noncusma_naics]].sum(axis=1),\n",
    "    'Total_C': census_byjobs.iloc[:, 2:].sum(axis=1)\n",
    "}\n",
    "\n",
    "# Create final grouped DataFrame\n",
    "census_bytariffs = pd.DataFrame(grouped_data)\n",
    "census_bytariffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516dc4f-87db-4cb8-8265-db06293e4927",
   "metadata": {},
   "source": [
    "# STEP 11: Processing and adding the data to Choropleth and Centroid GDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831fcbc6-e7dd-40f2-9bdd-9667495d6510",
   "metadata": {},
   "source": [
    "Add the data on employees (by primary residence) to the GDFs produced in Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27c4f08f-d794-4c9b-a112-d8913ee4f767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Auto_B</th>\n",
       "      <th>Alum_B</th>\n",
       "      <th>Steel_B</th>\n",
       "      <th>Cop_B</th>\n",
       "      <th>Lum_B</th>\n",
       "      <th>Ene_B</th>\n",
       "      <th>CUSMA_B</th>\n",
       "      <th>Total_B</th>\n",
       "      <th>Auto_E</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_E</th>\n",
       "      <th>Auto_C</th>\n",
       "      <th>Alum_C</th>\n",
       "      <th>Steel_C</th>\n",
       "      <th>Cop_C</th>\n",
       "      <th>Lum_C</th>\n",
       "      <th>Ene_C</th>\n",
       "      <th>CUSMA_C</th>\n",
       "      <th>Total_C</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>POINT (-53.25419 47.86225)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>POINT (-52.76054 47.72309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>POINT (-53.26649 47.73593)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>POINT (-52.71312 47.62177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>POINT (-52.7703 47.64725)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-115.3713 67.80897)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-95.88322 68.64144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-89.80822 68.53258)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-107.82111 67.68532)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POINT (-108.11145 66.83118)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID  Auto_B  Alum_B  Steel_B  Cop_B  Lum_B  Ene_B  \\\n",
       "0     2021S051610010001       0       1        1      0      2      0   \n",
       "1     2021S051610010002       0       0        0      0      0      0   \n",
       "2     2021S051610010003       0       1        1      0      4      0   \n",
       "3     2021S051610010004       0       1        1      1      0      2   \n",
       "4     2021S051610010005       2       1        1      0      0      0   \n",
       "...                 ...     ...     ...      ...    ...    ...    ...   \n",
       "5428  2021S051662080004       0       0        0      0      0      0   \n",
       "5429  2021S051662080005       0       0        0      0      0      0   \n",
       "5430  2021S051662080006       0       0        0      0      0      0   \n",
       "5431  2021S051662080007       0       0        0      0      0      0   \n",
       "5432  2021S051662080008       0       0        0      0      0      0   \n",
       "\n",
       "      CUSMA_B  Total_B  Auto_E  ...  Total_E  Auto_C  Alum_C  Steel_C  Cop_C  \\\n",
       "0          16       16       0  ...      844     0.0     1.0      1.0    0.0   \n",
       "1           2        2       0  ...       10     6.0     8.0      8.0    1.0   \n",
       "2           9        9       0  ...       54     0.0     1.0      2.0    0.0   \n",
       "3           7        7       0  ...       55     6.0     9.0      8.0    1.0   \n",
       "4           5        5       5  ...       29     6.0     9.0      8.0    1.0   \n",
       "...       ...      ...     ...  ...      ...     ...     ...      ...    ...   \n",
       "5428        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "5429        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "5430        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "5431        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "5432        0        0       0  ...        0     0.0     0.0      0.0    0.0   \n",
       "\n",
       "      Lum_C  Ene_C  CUSMA_C  Total_C                     geometry  \n",
       "0       5.0    0.0    613.0    613.0   POINT (-53.25419 47.86225)  \n",
       "1       3.0    7.0     82.0     82.0   POINT (-52.76054 47.72309)  \n",
       "2       8.0   28.0    258.0    258.0   POINT (-53.26649 47.73593)  \n",
       "3       4.0   13.0     95.0     95.0   POINT (-52.71312 47.62177)  \n",
       "4       4.0   15.0    107.0    107.0    POINT (-52.7703 47.64725)  \n",
       "...     ...    ...      ...      ...                          ...  \n",
       "5428    0.0    0.0      0.0      0.0   POINT (-115.3713 67.80897)  \n",
       "5429    0.0    0.0      0.0      0.0   POINT (-95.88322 68.64144)  \n",
       "5430    0.0    0.0      0.0      0.0   POINT (-89.80822 68.53258)  \n",
       "5431    0.0    0.0      0.0      0.0  POINT (-107.82111 67.68532)  \n",
       "5432    0.0    0.0      0.0      0.0  POINT (-108.11145 66.83118)  \n",
       "\n",
       "[5433 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = cent_gdf.merge(census_bytariffs, on='ADADGUID', how='left')\n",
    "centroids = centroids[['ADADGUID'] + [f'{tar}_B' for tar in tars] + [f'{tar}_E' for tar in tars] + [f'{tar}_C' for tar in tars] + ['geometry']]\n",
    "centroids = centroids.to_crs('EPSG:4326')\n",
    "centroids.to_file('centroids.geojson', driver='GeoJSON')\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5c7033e-0368-42c2-ada7-f5cc5c978e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Auto_3</th>\n",
       "      <th>Alum_3</th>\n",
       "      <th>Steel_3</th>\n",
       "      <th>Cop_3</th>\n",
       "      <th>Lum_3</th>\n",
       "      <th>Ene_3</th>\n",
       "      <th>CUSMA_3</th>\n",
       "      <th>Total_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165007</td>\n",
       "      <td>0.165007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>0.038679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.056954</td>\n",
       "      <td>0.056954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>0.018465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.020617</td>\n",
       "      <td>0.020617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID    Auto_3    Alum_3   Steel_3     Cop_3     Lum_3  \\\n",
       "0     2021S051610010001  0.000000  0.000269  0.000269  0.000000  0.001346   \n",
       "1     2021S051610010002  0.002830  0.003774  0.003774  0.000472  0.001415   \n",
       "2     2021S051610010003  0.000000  0.000221  0.000442  0.000000  0.001766   \n",
       "3     2021S051610010004  0.001166  0.001749  0.001555  0.000194  0.000777   \n",
       "4     2021S051610010005  0.001156  0.001734  0.001541  0.000193  0.000771   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "5428  2021S051662080004  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5429  2021S051662080005  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5430  2021S051662080006  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5431  2021S051662080007       NaN       NaN       NaN       NaN       NaN   \n",
       "5432  2021S051662080008       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "         Ene_3   CUSMA_3   Total_3  \n",
       "0     0.000000  0.165007  0.165007  \n",
       "1     0.003302  0.038679  0.038679  \n",
       "2     0.006181  0.056954  0.056954  \n",
       "3     0.002527  0.018465  0.018465  \n",
       "4     0.002890  0.020617  0.020617  \n",
       "...        ...       ...       ...  \n",
       "5428  0.000000  0.000000  0.000000  \n",
       "5429  0.000000  0.000000  0.000000  \n",
       "5430  0.000000  0.000000  0.000000  \n",
       "5431       NaN       NaN       NaN  \n",
       "5432       NaN       NaN       NaN  \n",
       "\n",
       "[5433 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_bytariffs = census_bytariffs.copy()\n",
    "\n",
    "for tar in tars:\n",
    "    tar_3 = f'{tar}_3'\n",
    "\n",
    "    perc_bytariffs[tar_3] = (\n",
    "        perc_bytariffs[f'{tar}_C']/perc_bytariffs['Census']\n",
    "    )\n",
    "\n",
    "perc_bytariffs = perc_bytariffs[['ADADGUID'] + [f'{tar}_3' for tar in tars]]\n",
    "perc_bytariffs['CUSMA_3'] = perc_bytariffs['CUSMA_3'].clip(upper=1)\n",
    "perc_bytariffs['Total_3'] = perc_bytariffs['Total_3'].clip(upper=1)\n",
    "perc_bytariffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e1cc893-492b-4034-beb6-32880e6170a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADADGUID</th>\n",
       "      <th>Auto_1</th>\n",
       "      <th>Alum_1</th>\n",
       "      <th>Steel_1</th>\n",
       "      <th>Cop_1</th>\n",
       "      <th>Lum_1</th>\n",
       "      <th>Ene_1</th>\n",
       "      <th>CUSMA_1</th>\n",
       "      <th>Total_1</th>\n",
       "      <th>Auto_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_2</th>\n",
       "      <th>Auto_3</th>\n",
       "      <th>Alum_3</th>\n",
       "      <th>Steel_3</th>\n",
       "      <th>Cop_3</th>\n",
       "      <th>Lum_3</th>\n",
       "      <th>Ene_3</th>\n",
       "      <th>CUSMA_3</th>\n",
       "      <th>Total_3</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021S051610010001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165007</td>\n",
       "      <td>0.165007</td>\n",
       "      <td>MULTIPOLYGON (((-53.51451 47.69912, -53.51464 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021S051610010002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>POLYGON ((-52.78543 47.80961, -52.78542 47.809...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021S051610010003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.056954</td>\n",
       "      <td>0.056954</td>\n",
       "      <td>MULTIPOLYGON (((-53.12645 47.81702, -53.12663 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021S051610010004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>POLYGON ((-52.66902 47.66588, -52.66898 47.665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021S051610010005</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.024631</td>\n",
       "      <td>0.00347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.020617</td>\n",
       "      <td>0.020617</td>\n",
       "      <td>POLYGON ((-52.73992 47.69568, -52.74026 47.694...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>2021S051662080004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((-115.34503 67.89695, -115.3453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2021S051662080005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((-95.82942 68.59941, -95.82932 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>2021S051662080006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MULTIPOLYGON (((-89.84909 68.53759, -89.84931 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>2021S051662080007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-107.9628 67.7012, -107.9628 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2021S051662080008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((-108.08644 66.85966, -108.0865...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5433 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADADGUID    Auto_1    Alum_1   Steel_1     Cop_1     Lum_1  \\\n",
       "0     2021S051610010001  0.000000  0.004566  0.004566  0.000000  0.009132   \n",
       "1     2021S051610010002  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     2021S051610010003  0.000000  0.003472  0.003472  0.000000  0.013889   \n",
       "3     2021S051610010004  0.000000  0.002283  0.002283  0.002283  0.000000   \n",
       "4     2021S051610010005  0.009852  0.004926  0.004926  0.000000  0.000000   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "5428  2021S051662080004  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5429  2021S051662080005  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5430  2021S051662080006  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5431  2021S051662080007       NaN       NaN       NaN       NaN       NaN   \n",
       "5432  2021S051662080008       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "         Ene_1   CUSMA_1   Total_1   Auto_2  ...   Total_2    Auto_3  \\\n",
       "0     0.000000  0.073059  0.073059  0.00000  ...  0.290034  0.000000   \n",
       "1     0.000000  0.030303  0.030303  0.00000  ...  0.025381  0.002830   \n",
       "2     0.000000  0.031250  0.031250  0.00000  ...  0.012900  0.000000   \n",
       "3     0.004566  0.015982  0.015982  0.00000  ...  0.006068  0.001166   \n",
       "4     0.000000  0.024631  0.024631  0.00347  ...  0.020125  0.001156   \n",
       "...        ...       ...       ...      ...  ...       ...       ...   \n",
       "5428  0.000000  0.000000  0.000000  0.00000  ...  0.000000  0.000000   \n",
       "5429  0.000000  0.000000  0.000000  0.00000  ...  0.000000  0.000000   \n",
       "5430  0.000000  0.000000  0.000000  0.00000  ...  0.000000  0.000000   \n",
       "5431       NaN       NaN       NaN      NaN  ...       NaN       NaN   \n",
       "5432       NaN       NaN       NaN      NaN  ...       NaN       NaN   \n",
       "\n",
       "        Alum_3   Steel_3     Cop_3     Lum_3     Ene_3   CUSMA_3   Total_3  \\\n",
       "0     0.000269  0.000269  0.000000  0.001346  0.000000  0.165007  0.165007   \n",
       "1     0.003774  0.003774  0.000472  0.001415  0.003302  0.038679  0.038679   \n",
       "2     0.000221  0.000442  0.000000  0.001766  0.006181  0.056954  0.056954   \n",
       "3     0.001749  0.001555  0.000194  0.000777  0.002527  0.018465  0.018465   \n",
       "4     0.001734  0.001541  0.000193  0.000771  0.002890  0.020617  0.020617   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5428  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5429  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5430  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5431       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "5432       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                               geometry  \n",
       "0     MULTIPOLYGON (((-53.51451 47.69912, -53.51464 ...  \n",
       "1     POLYGON ((-52.78543 47.80961, -52.78542 47.809...  \n",
       "2     MULTIPOLYGON (((-53.12645 47.81702, -53.12663 ...  \n",
       "3     POLYGON ((-52.66902 47.66588, -52.66898 47.665...  \n",
       "4     POLYGON ((-52.73992 47.69568, -52.74026 47.694...  \n",
       "...                                                 ...  \n",
       "5428  MULTIPOLYGON (((-115.34503 67.89695, -115.3453...  \n",
       "5429  MULTIPOLYGON (((-95.82942 68.59941, -95.82932 ...  \n",
       "5430  MULTIPOLYGON (((-89.84909 68.53759, -89.84931 ...  \n",
       "5431  MULTIPOLYGON (((-107.9628 67.7012, -107.9628 6...  \n",
       "5432  MULTIPOLYGON (((-108.08644 66.85966, -108.0865...  \n",
       "\n",
       "[5433 rows x 26 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choropleth = choro_gdf.merge(perc_bytariffs, on='ADADGUID', how='right')\n",
    "choropleth = choropleth[['ADADGUID'] + [f'{tar}_1' for tar in tars] + [f'{tar}_2' for tar in tars] + [f'{tar}_3' for tar in tars] + ['geometry']]\n",
    "choropleth = choropleth.to_crs('EPSG:4326')\n",
    "choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03e1ead8-0bf8-4feb-9c50-35df5f08b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "choropleth.to_file('choropleth.geojson', driver='GeoJSON')\n",
    "choropleth.to_file('choropleth.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377f1e6-da2d-4acb-b439-4cdec0139498",
   "metadata": {},
   "source": [
    "# CSV Trails\n",
    "\n",
    "for double-checking purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ac8c09d-1b88-4feb-9ce6-d5eed99efbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_grouped.drop(columns='geometry').to_csv('trail.csv', index=False)\n",
    "business_filter.drop(columns='geometry').to_csv('trail2.csv', index=False)\n",
    "business_census.to_csv('trail3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e0f5ad8-ad09-4703-bd87-470945cd7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "choro_cols.drop(columns='geometry').to_csv('trail4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "109a28ab-60ef-4f10-a7a5-a735ce372f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv('trail5.csv')\n",
    "jobs_rate.to_csv('trail6.csv')\n",
    "adjusted_jobs.to_csv('trail7.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
